[
  {
    "objectID": "user_guide/index.html",
    "href": "user_guide/index.html",
    "title": "User Guide",
    "section": "",
    "text": "This is the user guide for neuralyzer",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "user_guide/image_processing/contrast.html",
    "href": "user_guide/image_processing/contrast.html",
    "title": "Contrast and Brightness Adjustment",
    "section": "",
    "text": "These two filters are implemented with a single linear transform taking parameters “alpha” (\\(\\alpha\\)) and “beta” (\\(\\beta\\)). Pixel values are multiplied by \\(\\alpha\\) to adjust contrast, then have \\(\\beta\\) added to adjust brightness: \\[\ng(x) = \\alpha f(x) + \\beta\n\\] In effect the magnitude of \\(\\alpha\\) corresponds to the amount of contrast and the magnitude of \\(\\beta\\) corresponds to the amount of brightness.",
    "crumbs": [
      "Image Processing",
      "Contrast and Brightness Adjustment"
    ]
  },
  {
    "objectID": "user_guide/image_processing/bilateral_filter.html",
    "href": "user_guide/image_processing/bilateral_filter.html",
    "title": "Bilateral Filter",
    "section": "",
    "text": "https://docs.opencv.org/4.x/js_filtering_bilateralFilter.html\nhttps://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\nhttps://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html",
    "crumbs": [
      "Image Processing",
      "Bilateral Filter"
    ]
  },
  {
    "objectID": "user_guide/image_processing/bilateral_filter.html#references",
    "href": "user_guide/image_processing/bilateral_filter.html#references",
    "title": "Bilateral Filter",
    "section": "",
    "text": "https://docs.opencv.org/4.x/js_filtering_bilateralFilter.html\nhttps://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\nhttps://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html",
    "crumbs": [
      "Image Processing",
      "Bilateral Filter"
    ]
  },
  {
    "objectID": "user_guide/data_loading/JSON_loading.html",
    "href": "user_guide/data_loading/JSON_loading.html",
    "title": "JSON_loading",
    "section": "",
    "text": "Digital Event Series\nDigital event series are data represented by an ordered sequence of timestamps. Examples include spike timestamps from extracellular recordings or behavioral events (e.g. go cue, reward given).\n\n\nDigital Interval Series\n\n16 bit binary representation\n{\n  \"filepath\": \"ttl.bin\",\n  \"data_type\": \"digital_interval\",\n  \"name\": \"laser\",\n  \"format\": \"uint16\",\n  \"channel\": 2, // REQUIRED, bit (0 based) for channel of interest\n  \"transition\": \"rising\", //optional, \n  \"clock\": \"master\", //optional, clock signal to assign to these events\n  \"header_size\": 0 //optional, number of bytes to skip at start of file\n}\n\n\n\n\n\n\n\n\n\n\nElement\nDescription\nRequired?\nType\nNotes\n\n\n\n\nfilepath\nPath to binary file, relative to JSON file.\nYes\nstring\n\n\n\ndata_type\n\nYes\nstring\n“digital_interval”\n\n\nname\nName of the data once it is loaded into Neuralyzer\nYes\nstring\n\n\n\nformat\n\nYes\nstring\n“uint16”\n\n\nchannel\nSpecifies which bit in binary representation should be extracted as digital interval\nNo\nnumber\nDefault is 0. Valid values range from 0-15\n\n\nTransition\n“rising” will count a TTL interval as one extending from low-to-high transitions to high-to-low transitions. “falling” will count a TTL interval as one extending from high-to-low to low-to-high transitions.\nNo\nstring\nDefault is “rising”. Valid values are “rising” or “falling”.\n\n\nclock\nClock signal to associate with this digital interval\nNo\nstring\nThe clock string must match the name of a loaded clock signal.\n\n\nheader_size\nThis many bytes will be skipped at the beginning of the file before reading the rest.\nNo\nnumber\nDefault is 0. Accepted values range from 0 to size of file in bytes.\n\n\n\n\n\n\n\n\nCSV\n\n{\n  \"filepath\": \"ttl.bin\",\n  \"data_type\": \"digital_interval\",\n  \"name\": \"laser\",\n  \"format\": \"csv\"\n\n}\n\n\n\n\n\n\n\n\n\n\nElement\nDescription\nRequired?\nType\nNotes\n\n\n\n\nfilepath\nPath to csv file, relative to JSON file.\nYes\nstring\n\n\n\ndata_type\n\nYes\nstring\n“digital_interval”\n\n\nname\nName of the data once it is loaded into Neuralyzer\nYes\nstring\n\n\n\nformat\n\nYes\nstring\n“csv”",
    "crumbs": [
      "Data Loading",
      "JSON_loading"
    ]
  },
  {
    "objectID": "user_guide/behaviors/whisker.html",
    "href": "user_guide/behaviors/whisker.html",
    "title": "Whisker Tracking",
    "section": "",
    "text": "Load Whiskers\n\nSupported Whisker File Formats\n\n\n\n\n\n\nFile Format\nDescription\n\n\n\n\nJanelia\nBinary format output by janelia whisker tracker\n\n\nCSV\nEach row represents a 2d point (x,y) along the whisker. The points should be arranged from follicle to tip\n\n\nHDF5\n\n\n\n\n\n\nLoad Keypoints\n\n\nTrace Button\n\n\nLength Threshold\nWhisker segments below the length threshold will be discarded. Length threshold is in units of pixels\n\n\nWhisker Pad Selection\nThe whisker pad location in pixel coordinates. Candidate whiskers are ordered so that the base of the whisker is nearest the whisker pad. Whiskers with bases beyond some distance from the whisker pad can also be discarded.\n\n\nHead Orientation\nThe head orientation is the direction that the animal’s nose is pointing in the image. The head orientation is used to determine the identity of the whiskers in the frame (most posterior whisker is 0, next most posterior is 1, etc).\n\n\nNumber of Whiskers Selection\n\n\nExport Image and CSV Button\n\n\nFace Mask\nThe face mask corresponds to the part of the image belonging to the face. This can be used in several ways\n\nWhisker bases can be extended to always connect to the face mask. This eliminates jitter that can occur because of fur\nWhisker bases can be clipped to ensure that the whisker does not enter the face mask.\n\n\n\nJanelia Settings\n\n\nContact Detection",
    "crumbs": [
      "Behavioral Modules",
      "Whisker Tracking"
    ]
  },
  {
    "objectID": "labeling/mask.html",
    "href": "labeling/mask.html",
    "title": "Creating Mask Labels",
    "section": "",
    "text": "Creating mask labels is done through the GrabCut tool. Currently it can be opened through the Tongue Tracking widget."
  },
  {
    "objectID": "labeling/mask.html#grabcut-tool-operation",
    "href": "labeling/mask.html#grabcut-tool-operation",
    "title": "Creating Mask Labels",
    "section": "GrabCut Tool Operation",
    "text": "GrabCut Tool Operation\n\nSelecting ROI\nTo start creating a mask, left click and drag the mouse over the image to form a green rectangle as the region of interest. The objected intended to be masked should be completely within this rectangle. If a mistake is made the reset button returns the tool to the initial state.\nThe GrabCut algorithm works as such: the algorithm keeps track of the mask and for each iteration, attempts to refine it. In between iterations, the user can tweak the mask to provide feedback to the algorithm, which will be noted through subsequent iterations.\nAfter drawing an ROI the “Iterate Grabcut” button becomes functional. Using it completes one iteration of the GrabCut algorithm. The first usage of this button will show the initial mask created by the algorithm. Ideally the user should press this button throughout the editing process.\n\nOpacity of the displayed mask can be adjusted with the transparency slider\n\n\n\nUser Feedback\nIn between iterations the user has access to a drawing bush whose radius can be adjusted. It is used to paint feedback for the GrabCut algorithm, which it will take into account upon pressing the “Iterate Grabcut” button. The brush has four colors:\n\n“Definite Background”: Tells GrabCut the painted area is definitely not part of the mask.\n“Definite Foreground”: Tells GrabCut the painted area is definitely part of the mask.\n“Probable Background”: Suggests to GrabCut the painted area may not be part of the mask. GrabCut uses this information to create a better mask but may partially/fully disobey it.\n“Probable Foreground”: Suggests to GrabCut the painted area is likely part of the mask. GrabCut uses this information to create a better mask but may partially/fully disobey it.\n\n\n\nSaving and Exporting\nThe GrabCut tool may be exited at any time by pressing the “Exit” button. “Save and Exit” will exit the tool and save the mask into the main application and displayed in the media player. All created masks can be saved to disk using the “Save Drawn Masks” button in the Tongue Tracking widget."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neuralyzer",
    "section": "",
    "text": "Neuralyzer is a cross-platform software package designed for analyzing and visualizing common forms of data generated during systems neuroscience experiments."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Neuralyzer",
    "section": "Installation",
    "text": "Installation\nThe software comes as compiled .exe, .dmg or tar files and can be immediately used on Windows, Mac and Linux - no install required !\nLatest Release: link\nOld Releases: link"
  },
  {
    "objectID": "index.html#supported-data-types",
    "href": "index.html#supported-data-types",
    "title": "Neuralyzer",
    "section": "Supported Data Types",
    "text": "Supported Data Types\nSome currently supported data types include:\n\nMultimedia - High speed video and collections of images\nArrays of simple 2D shapes - Points, Lines, and masks that vary with time.\nDigital time series data - Events, timestamps,\nAnalog time series data - Continuous movement variables"
  },
  {
    "objectID": "index.html#how-documentation-is-organized",
    "href": "index.html#how-documentation-is-organized",
    "title": "Neuralyzer",
    "section": "How Documentation is Organized",
    "text": "How Documentation is Organized\nThis documentation will follow the quadrants of the Diátaxis documentation authoring framework\n\nTutorials\nHow-to Guides\nConcepts\nReference Guides"
  },
  {
    "objectID": "developer/media_widget.html",
    "href": "developer/media_widget.html",
    "title": "Media Widget",
    "section": "",
    "text": "The media widget is responsible for displaying data that can be visualized on a canvas. The types of data that can be displayed by the data manager include point data, line data, mask data, tensor data, interval data, and media data. Data currently in the data manager matching these types is displayed on the top left side. In this table, the user can click to enable the visibility of particular data in the accompanying media window canvas.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/media_widget.html#overview-and-data-display",
    "href": "developer/media_widget.html#overview-and-data-display",
    "title": "Media Widget",
    "section": "",
    "text": "The media widget is responsible for displaying data that can be visualized on a canvas. The types of data that can be displayed by the data manager include point data, line data, mask data, tensor data, interval data, and media data. Data currently in the data manager matching these types is displayed on the top left side. In this table, the user can click to enable the visibility of particular data in the accompanying media window canvas.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/media_widget.html#data-specific-interactions-and-manipulations",
    "href": "developer/media_widget.html#data-specific-interactions-and-manipulations",
    "title": "Media Widget",
    "section": "Data-Specific Interactions and Manipulations",
    "text": "Data-Specific Interactions and Manipulations\nClicking on a data item also brings up a sub-widget below the table, offering data type-specific manipulations. For example, this sub-widget would be responsible for changing attributes such as color, alpha value, marker type, etc., for point data within the media window. This sub-widget may also handle data-specific manipulations directly within the media window. For instance, the user might wish to click on a position in the media window to set it as the location for the currently displayed point. Alternatively, the user might click and hold to utilize a paintbrush-type function for extending or erasing mask data.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/media_widget.html#shared-components-and-common-interactions",
    "href": "developer/media_widget.html#shared-components-and-common-interactions",
    "title": "Media Widget",
    "section": "Shared Components and Common Interactions",
    "text": "Shared Components and Common Interactions\nThese data-specific sub-widgets may house common sub-widgets that are shared among others. For instance, color selection is a common feature for multiple data types. An interface for click, hover, and release interactions is common to multiple data types but may perform different actions, such as painting a mask or erasing the media foreground.\nNote that there is some overlap here with the data manager widget. For many data types the data manager widget includes the ability to view all data present in the data manager and select particular instances such as a point at a certain time and the user can delete that point. Consequently we will try to keep media window based manipulation to the media widget. \nThe media window is the widget that houses the actual canvas for display. It is also the owner of the specific drawing options and drawing routines onto the canvas. For instance if the user changes the marker size and color of point data the options that are updated are held by the media window. The media window uses qt-based drawing. It is also responsible for receiving mouse events inside its space and emits signals that other widgets can receive.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/Features/overview.html",
    "href": "developer/Features/overview.html",
    "title": "Features",
    "section": "",
    "text": "Documentation of some of the general widget types in Neuralyzer.",
    "crumbs": [
      "Features"
    ]
  },
  {
    "objectID": "developer/data_viewer_widget.html",
    "href": "developer/data_viewer_widget.html",
    "title": "Data Viewer Widget",
    "section": "",
    "text": "Data Viewer Widget Overview\nThe data viewer widget is designed for visualizing plots of time series data. It can operate on multiple distinct data types, such as analog time series, interval series, and event series. The widget contains a table of compatible data types and their corresponding keys, which can be selected for display in the viewer. It houses options to enable the visualization of different types and also includes an OpenGL canvas responsible for rendering the data according to user specifications.\n\n\nVisualization Capabilities\nMultiple pieces of data can be drawn on the same canvas. Some data can be drawn in an overlapping manner, or they may be drawn with different axis offsets. Both the Y and X axes are zoomable, and data-specific scaling can be applied to the Y-axis to allow data with different magnitudes to be easily visualized simultaneously. Drawing is synced to the time scroll bar in the main program, enabling the user to scroll through the plot while concurrently visualizing data in other widgets, such as movies collected at the same time.\nCritically, the data viewer has a concept of different sampling rates for different data types and accounts for this during drawing. For instance, event data from camera frames sampled at 500 frames per second can be plotted appropriately with electrophysiological data sampled at 30,000 Hertz. A “Time frame concept” within the data manager is responsible for handling these conversions between coordinate systems, and the data viewer is responsible for plotting this data appropriately.\n\n\nHandling Grouped Data and Custom Arrangement\nSome temporal data in neuroscience involves the concept of a group of signals that are collected simultaneously and would be visualized simultaneously. For instance, 32 channels recorded simultaneously from a silicon probe would be expected to have the same scaling properties and spacing. Consequently, groups of data like this should, by default, have mostly matching configuration options but maintain the ability to be adjusted individually as needed. For example, if there are dead channels on a probe, it should be easy for the user to turn these off from the display.\nThe arrangement of data in the viewer is also important. Again, considering a silicon probe, the numerical channel arrangement is often not the same as the spatial channel arrangement, though the user may wish to view this data spatially arranged. The user should be able to customize this arrangement.\n\n\nInteractive Analysis and Pre-processing\nThis representation may provide the user with information useful for certain data pre-processing tasks. For instance, the user may be able to determine a numerical threshold for event detection in a particular channel. Alternatively, in this view, the user may wish to determine the temporal range where it appears some behavior is taking place based on an analog signal change. For example, viewing the whisker angle versus time when zoomed out may be useful to identify times when the animal is whisking versus when it is stationary.\nThe user may even wish to interactively define events or intervals within this viewer window based on the temporal representation of data that would not be so easy to see in other widgets. Consequently, the data viewer is not just passive in its relationship with the data it is displaying but rather facilitates active engagement.",
    "crumbs": [
      "Data Viewer Widget"
    ]
  },
  {
    "objectID": "developer/data_manager.html",
    "href": "developer/data_manager.html",
    "title": "Data Manager",
    "section": "",
    "text": "The DataManager has 3 core functionalities",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_manager.html#time-frames",
    "href": "developer/data_manager.html#time-frames",
    "title": "Data Manager",
    "section": "Time Frames",
    "text": "Time Frames",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_manager.html#observer-framework",
    "href": "developer/data_manager.html#observer-framework",
    "title": "Data Manager",
    "section": "Observer Framework",
    "text": "Observer Framework",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_manager.html#data-types",
    "href": "developer/data_manager.html#data-types",
    "title": "Data Manager",
    "section": "Data Types",
    "text": "Data Types\n\nPoint\nA Point represents a 2 dimensional (x, y) coordinate, which may vary in time. The PointData structure can hold multiple points per unit time.\n\n\n\nExamples of Point Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLine\nA Line represents a 2 dimensional (x,y) collection of points, which may vary with time. The collection of points is ordered, meaning that each point is positioned relative to its neighbors. The LineData structure can hold multiple lines per unit time.\n\n\n\nExamples of Line Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrently, lines are represented by a raw list of points. One could imagine lines being parameterized in different ways, such as the coefficients of a polynomial fit. For many calculations, the parameterized version of a line may be less memory intensive and more efficient.\n\n\nMask\nA mask represents a 2 dimensional collection of points, which may vary with time. Compared to a Line, the points in a Mask are not ordered. These would correspond to something like a binary segmentation mask over an image. The MaskData structure can hold multiple masks per unit time.\n\n\n\nExamples of Mask Data\n\n\n\n\nBinary Semantic Segmentation Labels\n\n\n\n\n\n\n\n\n\nA mask may just be thought as a raw pixel, by pixel definition of a shape. Shapes could be defined as bounding boxes, circles, polygons, etc. It may one day be useful to describe shapes in other ways compared to the raw pixel-by-pixel definition.\n\n\nTensors\nTensors are N-Dimensional data structures, and consequently very flexible containers for complex data. A concrete use would be to store a Height x Width x Channel array for different timepoints during an experiment. These may be the features output from an encoder neural network that processes a video.\n\n\n\nExamples of Tensor Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalog Time Series\nAn analog time series has values that can vary continuously\n\n\n\nExamples of Analog Time Series Data\n\n\n\n\nVoltage traces from electrode recordings\n\n\nFluorescence intensity traces from Calcium imaging\n\n\n\n\n\n\n\n\nDigital Event Series\nA digital event represents an ordered sequence of events, where each event is represented as a single instance in time. For instance, spike times from electrophysiology\n\n\n\nExamples of Event Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Interval Series\n\n\n\nExamples of Interval Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia\nMedia is a sequence of images.\n\nImage\n\n\n\nExamples of Image Data\n\n\n\n\nImage sequence from two photon calcium imaging experiment\n\n\n\n\n\n\n\n\n\n\n\nVideo\n\n\n\nExamples of Video Data\n\n\n\n\nMP4 video from high speed scientific camera of behavior\n\n\n\n\n\n\n\n\n\n\n\n\nTime Frame",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "developer/contributing_code.html",
    "href": "developer/contributing_code.html",
    "title": "Contributing Code",
    "section": "",
    "text": "Header files should use the hpp suffix, and source files should use the cpp suffix\nIncludes should follow the “Lakos” include order, that is\n\nThe prototype/interface header for this implementation (ie, the .h/.hh file that corresponds to this .cpp/.cc file).\nOther headers from the same project, as needed.\nHeaders from other non-standard, non-system libraries (for example, Qt, Eigen, etc).\nHeaders from other “almost-standard” libraries (for example, Boost)\nStandard C++ headers (for example, iostream, functional, etc.)\nStandard C headers (for example, cstdint, dirent.h, etc.)\n\nPrefer returning std::optional as a mechanism of error handling\nThis is a scientific computing library. Performance is critical. Helping the user to understand where errors have occurred is helpful, but keeping the program alive after an error is not critical. Functions should fail gracefully and provide informative error messages when they do. Logging should use spdlog.\nPrefer free functions as much as possible. Ideally, class member functions will be simple and pass member variables to free functions.\nPrefer standard library algorithms where possible\nPublic member functions and free function declarations should include doxygen comments above them. Private member function definitions should include doxygen comments above them.\nPrefer forward declarations in header files\nThis is a C++20 project. Prefer standard library algorithms and std::ranges where possible.",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#design-guidelines",
    "href": "developer/contributing_code.html#design-guidelines",
    "title": "Contributing Code",
    "section": "",
    "text": "Header files should use the hpp suffix, and source files should use the cpp suffix\nIncludes should follow the “Lakos” include order, that is\n\nThe prototype/interface header for this implementation (ie, the .h/.hh file that corresponds to this .cpp/.cc file).\nOther headers from the same project, as needed.\nHeaders from other non-standard, non-system libraries (for example, Qt, Eigen, etc).\nHeaders from other “almost-standard” libraries (for example, Boost)\nStandard C++ headers (for example, iostream, functional, etc.)\nStandard C headers (for example, cstdint, dirent.h, etc.)\n\nPrefer returning std::optional as a mechanism of error handling\nThis is a scientific computing library. Performance is critical. Helping the user to understand where errors have occurred is helpful, but keeping the program alive after an error is not critical. Functions should fail gracefully and provide informative error messages when they do. Logging should use spdlog.\nPrefer free functions as much as possible. Ideally, class member functions will be simple and pass member variables to free functions.\nPrefer standard library algorithms where possible\nPublic member functions and free function declarations should include doxygen comments above them. Private member function definitions should include doxygen comments above them.\nPrefer forward declarations in header files\nThis is a C++20 project. Prefer standard library algorithms and std::ranges where possible.",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#before-you-submit-a-pull-request",
    "href": "developer/contributing_code.html#before-you-submit-a-pull-request",
    "title": "Contributing Code",
    "section": "Before You Submit a Pull Request",
    "text": "Before You Submit a Pull Request\n\nClang Format\nPlease make sure to run clang-format on all of your submitted files with the style guidelines in the base directory. A CI check will ensure that this happens upon pull request. You can read more about clang-format here:\nhttps://clang.llvm.org/docs/ClangFormat.html\n\n\nClang Tidy\nPlease make sure to run clang-tidy on all of your submitted files with the style guidelines in the base directory. A CI check will ensure that this happens upon pull request. You can read more about clang-tidy here:\nhttps://clang.llvm.org/extra/clang-tidy/",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#testing",
    "href": "developer/contributing_code.html#testing",
    "title": "Contributing Code",
    "section": "Testing",
    "text": "Testing\n\nTesting is performed with Catch2. \nThe component being tested generally has two TEST_CASE parts. The first will test the “happy path” to ensure that the computations work as expected. Different SECTIONs will be used for different computations. A second TEST_CASE will handle error handling and edge cases. Each SECTION will be for a different edge case / error.\nUse descriptive names for each test.\nTEST_CASEs should also use useful tags.\nUse REQUIRE instead of CHECK\nSimple setup can be performed in the beginning of a TEST_CASE. Fixtures are only necessary for complex setup/teardown.\nPrefer Catch::Matchers::WithinRel to Catch::Approx\nTest files are included in the same folder as a given translation unit. They should have the same name as the header file with the extension “.test.cpp”. For example mask_to_line.hpp and mask_to_line.cpp will have the test file mask_to_line.test.cpp.",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#further-resources-and-references",
    "href": "developer/contributing_code.html#further-resources-and-references",
    "title": "Contributing Code",
    "section": "Further Resources and References",
    "text": "Further Resources and References\n\nLLM Support\nA configuration file for a plain text generator, repo-to-text, is included in the top level source directory. This can generate a single text file for the entire Neuralyzer repository which can be easily pasted into a LLM of choice.\n\n\nTesting\n\nC++ Development\nMike Shah has an excellent modern C++ design series on youtube. Episodes are a nice ~20 minute length:\nModern Cpp series by Mike Shah\n\n\nGraphics Programming\nMike Shah also has a series on modern OpenGL on youtube:\nIntroduction to OpenGL",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/data_manager_widget.html",
    "href": "developer/data_manager_widget.html",
    "title": "Data Manager Widget",
    "section": "",
    "text": "Data Manager Widget Overview\nThe data manager widget serves as the main user interface for interacting with all data currently loaded into the program. At its top, the widget displays all keys currently in the data manager along with their corresponding data types. It enables the user to specify the folder for saving data. Additionally, users can create new, initially blank data sets, which can subsequently be populated through further manipulations and other widgets.\nWhen a user selects an entry in the top table, a data type-specific soft widget is populated. This widget presents the user with various features of the selected data. For example, when dealing with point data, it shows a table listing every available point within that data set and its associated frame. The user has the ability to scroll through this table; clicking an entry causes the time displayed by the rest of the program to jump to that point’s frame. Users can perform several data manipulations via these specific widgets. For instance, using the point widget, a user can delete any specific point. They can also opt to move a specific point to another point data set available in the manager.\n\n\nData Saving Functionality\nThe data manager widget also functions as the primary interface for saving data to disk. It features a sub-widget interface where the user can select the desired file output type, and specific options for that output type are then displayed. For instance, if a user is viewing point data, they can choose to output CSV files and will be presented with various CSV saving options, such as selecting the delimiter and deciding whether a header should be included, etc.",
    "crumbs": [
      "Data Manager Widget"
    ]
  },
  {
    "objectID": "developer/Features/Collapsible_Widget.html",
    "href": "developer/Features/Collapsible_Widget.html",
    "title": "Collapsible Widget",
    "section": "",
    "text": "We have a Collapsible Widget called a “Section” available. This kind of widget can expand to display the contents of the widget. This is useful for making an interface appear less cluttered.\n\nGeneral process for to add collapsible Widget:\nQT Designer:\n\nEnsure the parent widget is in a vertical layout\nCreate QWidget inside and promote it to a “Section”\nCreate another QWidget within that QWidget. The inner QWidget will hold all the contents of the section.\nPopulate this inner QWidget with widgets as normal.\n\nCode part:\n\nCall autoSetContentLayout() on the Section QWidget after setupUi.\nOptionally, calling setTitle(\"title\") will give it a title.",
    "crumbs": [
      "Features",
      "Collapsible Widget"
    ]
  },
  {
    "objectID": "developer/file_io.html",
    "href": "developer/file_io.html",
    "title": "File IO",
    "section": "",
    "text": "Because Neuralizer is compatible with a wide range of data, its file IO needs to support a wide range of file formats. Some of these file formats will be pre-subscribed, such as data acquisition-specific formats for electrophysiology. Others are more specific to this package, such as for line data that varies over time. We must also be aware from the start that some electrophysiology file sizes can be expected to be larger than easy to work with on a regular desktop machine. For instance, Neuropixel probes record almost 400 channels at 20 kHz and are becoming more routine for use. Consequently, multiple file formats should have the ability to be easily memory-mapped and loaded from disk rather than loading the entire file into RAM.\n\n\n\nAnother important consideration from the start is that many of these data types will be incrementally adjusted. For instance, processing a video sequence frame by frame or manually adjusting the output of an automated algorithm requires changing some subset of data in a much larger scheme. For some of these file types that are greater than hundreds of megabytes, resaving an entire file for point manipulations could be onerous and time-consuming. Consequently, for some file types, it would be advantageous to use a key-value database type structure that allows us to easily make incremental adjustments and only save those changes, consequently saving data much more quickly. To my knowledge, this process is quite common in the wild but uncommon in neuroscience.\n\n\n\nThe process of data serialization and deserialization will be accomplished with the Captain Proto library. This is able to easily create binary files from more complex data structures, such as those that hold multiple lines of varying size per unit time. This library can define output file structures that are purely binary and would be saved and loaded as entire objects. Alternatively, different definitions can be used to save objects as key-value pairs; for instance, each time point can be the key and the data at that time can be the value.\n\n\n\nCaptain Proto does not perform memory mapping itself. Memory mapping is different across different types of file systems, so to maintain cross-platform use, we will need to either specify different interfaces for interacting with Captain Proto or we could use another third-party library that does this for us. Boost.Interprocess is commonly cited for this purpose, but there are others.\n\n\n\nFor key-value database structures, there are multiple libraries available. Many of these are mature and designed to work with servers of extremely large datasets, and some have been developed by very large companies. One of the most popular is called LMDB, but in my test cases, this appears to be not as great with Windows. Using this library requires specifying some maximum file size; on Linux, the resulting file size is only the size of the data, but with my testing on Windows, this large maximum file size seems to persist. An alternative database is RocksDB. This software is developed by Facebook, seems to be quite mature, and should also be able to save as a key-value pair across platforms.\n\n\n\nCurrently, the data that would benefit from key-value updates is only theoretical. Having a line for whiskers for each frame in a high-speed video of up to 200,000 frames results in a file size that is almost 300 MB. However, saving a binary file in its entirety when making whisker-specific updates through manual curation still takes less than a second to save and is not noticeable to the user. Consequently, I think prioritizing having binary outputs to save entire files and memory mapping of those binary file types that are read-only, such as for Neuropixel analog traces, may be the most desirable next feature. Key-value pairs with something like RocksDB should be remembered for the future, but I am going to make that less of a priority until I see a clear use case that would benefit.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#overview-of-file-io-requirements",
    "href": "developer/file_io.html#overview-of-file-io-requirements",
    "title": "File IO",
    "section": "",
    "text": "Because Neuralizer is compatible with a wide range of data, its file IO needs to support a wide range of file formats. Some of these file formats will be pre-subscribed, such as data acquisition-specific formats for electrophysiology. Others are more specific to this package, such as for line data that varies over time. We must also be aware from the start that some electrophysiology file sizes can be expected to be larger than easy to work with on a regular desktop machine. For instance, Neuropixel probes record almost 400 channels at 20 kHz and are becoming more routine for use. Consequently, multiple file formats should have the ability to be easily memory-mapped and loaded from disk rather than loading the entire file into RAM.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#incremental-data-adjustments-and-key-value-stores",
    "href": "developer/file_io.html#incremental-data-adjustments-and-key-value-stores",
    "title": "File IO",
    "section": "",
    "text": "Another important consideration from the start is that many of these data types will be incrementally adjusted. For instance, processing a video sequence frame by frame or manually adjusting the output of an automated algorithm requires changing some subset of data in a much larger scheme. For some of these file types that are greater than hundreds of megabytes, resaving an entire file for point manipulations could be onerous and time-consuming. Consequently, for some file types, it would be advantageous to use a key-value database type structure that allows us to easily make incremental adjustments and only save those changes, consequently saving data much more quickly. To my knowledge, this process is quite common in the wild but uncommon in neuroscience.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#serialization-with-captain-proto",
    "href": "developer/file_io.html#serialization-with-captain-proto",
    "title": "File IO",
    "section": "",
    "text": "The process of data serialization and deserialization will be accomplished with the Captain Proto library. This is able to easily create binary files from more complex data structures, such as those that hold multiple lines of varying size per unit time. This library can define output file structures that are purely binary and would be saved and loaded as entire objects. Alternatively, different definitions can be used to save objects as key-value pairs; for instance, each time point can be the key and the data at that time can be the value.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#memory-mapping-implementation",
    "href": "developer/file_io.html#memory-mapping-implementation",
    "title": "File IO",
    "section": "",
    "text": "Captain Proto does not perform memory mapping itself. Memory mapping is different across different types of file systems, so to maintain cross-platform use, we will need to either specify different interfaces for interacting with Captain Proto or we could use another third-party library that does this for us. Boost.Interprocess is commonly cited for this purpose, but there are others.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#key-value-database-libraries",
    "href": "developer/file_io.html#key-value-database-libraries",
    "title": "File IO",
    "section": "",
    "text": "For key-value database structures, there are multiple libraries available. Many of these are mature and designed to work with servers of extremely large datasets, and some have been developed by very large companies. One of the most popular is called LMDB, but in my test cases, this appears to be not as great with Windows. Using this library requires specifying some maximum file size; on Linux, the resulting file size is only the size of the data, but with my testing on Windows, this large maximum file size seems to persist. An alternative database is RocksDB. This software is developed by Facebook, seems to be quite mature, and should also be able to save as a key-value pair across platforms.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#prioritization-and-future-considerations",
    "href": "developer/file_io.html#prioritization-and-future-considerations",
    "title": "File IO",
    "section": "",
    "text": "Currently, the data that would benefit from key-value updates is only theoretical. Having a line for whiskers for each frame in a high-speed video of up to 200,000 frames results in a file size that is almost 300 MB. However, saving a binary file in its entirety when making whisker-specific updates through manual curation still takes less than a second to save and is not noticeable to the user. Consequently, I think prioritizing having binary outputs to save entire files and memory mapping of those binary file types that are read-only, such as for Neuropixel analog traces, may be the most desirable next feature. Key-value pairs with something like RocksDB should be remembered for the future, but I am going to make that less of a priority until I see a clear use case that would benefit.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "user_guide/behaviors/tongue.html",
    "href": "user_guide/behaviors/tongue.html",
    "title": "Tongue Tracking",
    "section": "",
    "text": "The Tongue Tracking widget deals with operations related to the tongue.",
    "crumbs": [
      "Behavioral Modules",
      "Tongue Tracking"
    ]
  },
  {
    "objectID": "user_guide/behaviors/tongue.html#loading",
    "href": "user_guide/behaviors/tongue.html#loading",
    "title": "Tongue Tracking",
    "section": "Loading",
    "text": "Loading\nTongue masks can be loaded through the sparse HDF5 format or binary images (where white is part of the mask, black is not).\nJaw keypoint tracking can also be loaded through CSV format. The first column should indicate frame number, the next indicating \\(x\\) position and the next \\(y\\) position.",
    "crumbs": [
      "Behavioral Modules",
      "Tongue Tracking"
    ]
  },
  {
    "objectID": "user_guide/behaviors/tongue.html#grabcut-tool",
    "href": "user_guide/behaviors/tongue.html#grabcut-tool",
    "title": "Tongue Tracking",
    "section": "GrabCut Tool",
    "text": "GrabCut Tool\nDocumentation on the GrabCut tool can be found here.",
    "crumbs": [
      "Behavioral Modules",
      "Tongue Tracking"
    ]
  },
  {
    "objectID": "user_guide/data_transformations/overview.html",
    "href": "user_guide/data_transformations/overview.html",
    "title": "Data Transformations",
    "section": "",
    "text": "Data transformations are operations we perform on one kind of data that result in another kind of data.\nTransformations supported by Neuralyzer are listed below:",
    "crumbs": [
      "Data Transformations",
      "Data Transformations"
    ]
  },
  {
    "objectID": "user_guide/data_transformations/overview.html#transformations",
    "href": "user_guide/data_transformations/overview.html#transformations",
    "title": "Data Transformations",
    "section": "Transformations",
    "text": "Transformations\n\nAnalog Time Series\n\nEvent Detection by Threshold Crossing\nGenerate events from a time series by comparing signal to some threshold value.\nThreshold Value:\nThe numerical level the signal must cross to be considered an event. The signal will be compared directly against this value based on the selected direction.\nThreshold Direction:\nHow the signal must cross the Threshold Value to trigger an event:\n\nPositive (Rising): Detects an event only when the signal value increases and crosses above the Threshold Value.\nNegative (Falling): Detects an event only when the signal value decreases and crosses below the Threshold Value.\nAbsolute (Magnitude): Detects an event when the absolute value of the signal (abs(signal)) rises above the Threshold Value. This detects crossings away from zero on either the positive or negative side.\n\nLockout Time (Samples):\nThe minimum number of samples that must pass after an event is detected before another threshold crossing can trigger a new event. Enter 0 (or less) to disable the lockout, allowing consecutive samples to trigger events if they cross the threshold. This helps prevent multiple detections from a single noisy crossing.\n\n\nFind Peaks\nAttempts to find peaks in analog time series (local maxima or minima).\n\n\nInstantaneous Amplitude Calculation\nDetermine the instantaneous amplitude of an oscillatory time series. uses Hilbert Transform.\n\n\nInstantaneous Phase Calculation\nDetermine the instantaneous phase of an oscillatory time series. Uses Hilbert Transform.\n\n\nInterval Detection\nDetermine an interval range where an angle signal is above (or below) a threshold value. Returns the beginning and end of the above/below threshold time period.\nThreshold Value:\nDescription: Enter the numerical level the signal must cross to be considered an event. The signal will be compared directly against this value based on the selected direction. The interval will be defined from the first to last sample that are above or below the Threshold Value.\nThreshold Direction:\nDescription: Select how the signal must cross the Threshold Value to trigger an interval:\n\nPositive (Rising): Detects an interval only when the signal value increases and remains above the Threshold Value.\nNegative (Falling): Detects an event only when the signal value decreases and remains below the Threshold Value.\nAbsolute (Magnitude): Detects an event when the absolute value of the signal (abs(signal)) rises above the Threshold Value. This detects crossings away from zero on either the positive or negative side. Once the absolute value is smaller than the abs(signal), the interval has ended.\n\nLockout Time (Samples):\nDescription: Specify the minimum number of samples that must pass after an interval has ended before another threshold crossing can trigger a new event. Enter 0 (or less) to disable the lockout.\nMinimum Duration (Samples):\nDescription: Specify the minimum number of samples that must be in an interval to be included. Threshold crossings with durations shorter than Minimum Duration will not be included in result.\n\n\n\nMasks\n\nArea\nTotal area of the mask in a frame is calculated.",
    "crumbs": [
      "Data Transformations",
      "Data Transformations"
    ]
  },
  {
    "objectID": "user_guide/machine_learning/ML_intro.html",
    "href": "user_guide/machine_learning/ML_intro.html",
    "title": "Overview",
    "section": "",
    "text": "The Machine Learning Widget allows us to fit models of relationships between multiple features of our data and then make predictions. This can be useful for semi-automated annotation of datasets, where the user labels some training data, and then predicts the remaining unlabeled frames. Then annotations can then be easily compared with the video data.",
    "crumbs": [
      "Machine Learning",
      "Overview"
    ]
  }
]