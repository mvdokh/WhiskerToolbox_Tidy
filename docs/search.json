[
  {
    "objectID": "user_guide/index.html",
    "href": "user_guide/index.html",
    "title": "User Guide",
    "section": "",
    "text": "This is the user guide for neuralyzer",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "user_guide/image_processing/contrast.html",
    "href": "user_guide/image_processing/contrast.html",
    "title": "Contrast and Brightness Adjustment",
    "section": "",
    "text": "These two filters are implemented with a single linear transform taking parameters “alpha” (\\(\\alpha\\)) and “beta” (\\(\\beta\\)). Pixel values are multiplied by \\(\\alpha\\) to adjust contrast, then have \\(\\beta\\) added to adjust brightness: \\[\ng(x) = \\alpha f(x) + \\beta\n\\] In effect the magnitude of \\(\\alpha\\) corresponds to the amount of contrast and the magnitude of \\(\\beta\\) corresponds to the amount of brightness.",
    "crumbs": [
      "Image Processing",
      "Contrast and Brightness Adjustment"
    ]
  },
  {
    "objectID": "user_guide/image_processing/bilateral_filter.html",
    "href": "user_guide/image_processing/bilateral_filter.html",
    "title": "Bilateral Filter",
    "section": "",
    "text": "https://docs.opencv.org/4.x/js_filtering_bilateralFilter.html\nhttps://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\nhttps://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html",
    "crumbs": [
      "Image Processing",
      "Bilateral Filter"
    ]
  },
  {
    "objectID": "user_guide/image_processing/bilateral_filter.html#references",
    "href": "user_guide/image_processing/bilateral_filter.html#references",
    "title": "Bilateral Filter",
    "section": "",
    "text": "https://docs.opencv.org/4.x/js_filtering_bilateralFilter.html\nhttps://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\nhttps://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html",
    "crumbs": [
      "Image Processing",
      "Bilateral Filter"
    ]
  },
  {
    "objectID": "user_guide/data_loading/JSON_loading.html",
    "href": "user_guide/data_loading/JSON_loading.html",
    "title": "JSON_loading",
    "section": "",
    "text": "Digital Event Series\nDigital event series are data represented by an ordered sequence of timestamps. Examples include spike timestamps from extracellular recordings or behavioral events (e.g. go cue, reward given).\n\n\nDigital Interval Series\n\n16 bit binary representation\n{\n  \"filepath\": \"ttl.bin\",\n  \"data_type\": \"digital_interval\",\n  \"name\": \"laser\",\n  \"format\": \"uint16\",\n  \"channel\": 2, // REQUIRED, bit (0 based) for channel of interest\n  \"transition\": \"rising\", //optional, \n  \"clock\": \"master\", //optional, clock signal to assign to these events\n  \"header_size\": 0 //optional, number of bytes to skip at start of file\n}\n\n\n\n\n\n\n\n\n\n\nElement\nDescription\nRequired?\nType\nNotes\n\n\n\n\nfilepath\nPath to binary file, relative to JSON file.\nYes\nstring\n\n\n\ndata_type\n\nYes\nstring\n“digital_interval”\n\n\nname\nName of the data once it is loaded into Neuralyzer\nYes\nstring\n\n\n\nformat\n\nYes\nstring\n“uint16”\n\n\nchannel\nSpecifies which bit in binary representation should be extracted as digital interval\nNo\nnumber\nDefault is 0. Valid values range from 0-15\n\n\nTransition\n“rising” will count a TTL interval as one extending from low-to-high transitions to high-to-low transitions. “falling” will count a TTL interval as one extending from high-to-low to low-to-high transitions.\nNo\nstring\nDefault is “rising”. Valid values are “rising” or “falling”.\n\n\nclock\nClock signal to associate with this digital interval\nNo\nstring\nThe clock string must match the name of a loaded clock signal.\n\n\nheader_size\nThis many bytes will be skipped at the beginning of the file before reading the rest.\nNo\nnumber\nDefault is 0. Accepted values range from 0 to size of file in bytes.\n\n\n\n\n\n\n\n\nCSV\n\n{\n  \"filepath\": \"ttl.bin\",\n  \"data_type\": \"digital_interval\",\n  \"name\": \"laser\",\n  \"format\": \"csv\"\n\n}\n\n\n\n\n\n\n\n\n\n\nElement\nDescription\nRequired?\nType\nNotes\n\n\n\n\nfilepath\nPath to csv file, relative to JSON file.\nYes\nstring\n\n\n\ndata_type\n\nYes\nstring\n“digital_interval”\n\n\nname\nName of the data once it is loaded into Neuralyzer\nYes\nstring\n\n\n\nformat\n\nYes\nstring\n“csv”",
    "crumbs": [
      "Data Loading",
      "JSON_loading"
    ]
  },
  {
    "objectID": "user_guide/behaviors/whisker.html",
    "href": "user_guide/behaviors/whisker.html",
    "title": "Whisker Tracking",
    "section": "",
    "text": "Load Whiskers\n\nSupported Whisker File Formats\n\n\n\n\n\n\nFile Format\nDescription\n\n\n\n\nJanelia\nBinary format output by janelia whisker tracker\n\n\nCSV\nEach row represents a 2d point (x,y) along the whisker. The points should be arranged from follicle to tip\n\n\nHDF5\n\n\n\n\n\n\nLoad Keypoints\n\n\nTrace Button\n\n\nLength Threshold\nWhisker segments below the length threshold will be discarded. Length threshold is in units of pixels\n\n\nWhisker Pad Selection\nThe whisker pad location in pixel coordinates. Candidate whiskers are ordered so that the base of the whisker is nearest the whisker pad. Whiskers with bases beyond some distance from the whisker pad can also be discarded.\n\n\nHead Orientation\nThe head orientation is the direction that the animal’s nose is pointing in the image. The head orientation is used to determine the identity of the whiskers in the frame (most posterior whisker is 0, next most posterior is 1, etc).\n\n\nNumber of Whiskers Selection\n\n\nExport Image and CSV Button\n\n\nFace Mask\nThe face mask corresponds to the part of the image belonging to the face. This can be used in several ways\n\nWhisker bases can be extended to always connect to the face mask. This eliminates jitter that can occur because of fur\nWhisker bases can be clipped to ensure that the whisker does not enter the face mask.\n\n\n\nJanelia Settings\n\n\nContact Detection",
    "crumbs": [
      "Behavioral Modules",
      "Whisker Tracking"
    ]
  },
  {
    "objectID": "labeling/mask.html",
    "href": "labeling/mask.html",
    "title": "Creating Mask Labels",
    "section": "",
    "text": "Creating mask labels is done through the GrabCut tool. Currently it can be opened through the Tongue Tracking widget."
  },
  {
    "objectID": "labeling/mask.html#grabcut-tool-operation",
    "href": "labeling/mask.html#grabcut-tool-operation",
    "title": "Creating Mask Labels",
    "section": "GrabCut Tool Operation",
    "text": "GrabCut Tool Operation\n\nSelecting ROI\nTo start creating a mask, left click and drag the mouse over the image to form a green rectangle as the region of interest. The objected intended to be masked should be completely within this rectangle. If a mistake is made the reset button returns the tool to the initial state.\nThe GrabCut algorithm works as such: the algorithm keeps track of the mask and for each iteration, attempts to refine it. In between iterations, the user can tweak the mask to provide feedback to the algorithm, which will be noted through subsequent iterations.\nAfter drawing an ROI the “Iterate Grabcut” button becomes functional. Using it completes one iteration of the GrabCut algorithm. The first usage of this button will show the initial mask created by the algorithm. Ideally the user should press this button throughout the editing process.\n\nOpacity of the displayed mask can be adjusted with the transparency slider\n\n\n\nUser Feedback\nIn between iterations the user has access to a drawing bush whose radius can be adjusted. It is used to paint feedback for the GrabCut algorithm, which it will take into account upon pressing the “Iterate Grabcut” button. The brush has four colors:\n\n“Definite Background”: Tells GrabCut the painted area is definitely not part of the mask.\n“Definite Foreground”: Tells GrabCut the painted area is definitely part of the mask.\n“Probable Background”: Suggests to GrabCut the painted area may not be part of the mask. GrabCut uses this information to create a better mask but may partially/fully disobey it.\n“Probable Foreground”: Suggests to GrabCut the painted area is likely part of the mask. GrabCut uses this information to create a better mask but may partially/fully disobey it.\n\n\n\nSaving and Exporting\nThe GrabCut tool may be exited at any time by pressing the “Exit” button. “Save and Exit” will exit the tool and save the mask into the main application and displayed in the media player. All created masks can be saved to disk using the “Save Drawn Masks” button in the Tongue Tracking widget."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neuralyzer",
    "section": "",
    "text": "Neuralyzer is a cross-platform software package designed for analyzing and visualizing common forms of data generated during systems neuroscience experiments."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Neuralyzer",
    "section": "Installation",
    "text": "Installation\nThe software comes as compiled .exe, .dmg or tar files and can be immediately used on Windows, Mac and Linux - no install required !\nLatest Release: link\nOld Releases: link"
  },
  {
    "objectID": "index.html#supported-data-types",
    "href": "index.html#supported-data-types",
    "title": "Neuralyzer",
    "section": "Supported Data Types",
    "text": "Supported Data Types\nSome currently supported data types include:\n\nMultimedia - High speed video and collections of images\nArrays of simple 2D shapes - Points, Lines, and masks that vary with time.\nDigital time series data - Events, timestamps,\nAnalog time series data - Continuous movement variables"
  },
  {
    "objectID": "index.html#how-documentation-is-organized",
    "href": "index.html#how-documentation-is-organized",
    "title": "Neuralyzer",
    "section": "How Documentation is Organized",
    "text": "How Documentation is Organized\nThis documentation will follow the quadrants of the Diátaxis documentation authoring framework\n\nTutorials\nHow-to Guides\nConcepts\nReference Guides"
  },
  {
    "objectID": "developer/point_display_options.html",
    "href": "developer/point_display_options.html",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "The display system in WhiskerToolbox allows users to customize the visual appearance of various data types including points and lines through configurable display options.\n\n\n\n\n\n\nRange: 1-50 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 5 pixels\n\n\n\n\nThe system supports six different marker shapes:\n\nCircle (default) - Filled circular marker\nSquare - Filled rectangular marker\n\nTriangle - Filled triangular marker pointing upward\nCross - Plus sign (+) shaped marker\nX - X-shaped marker (×)\nDiamond - Diamond shaped marker (rotated square)\n\n\n\n\n\nPoint configuration is stored in the PointDisplayOptions structure\nUI controls are synchronized to prevent conflicts\nReal-time updates are supported via Qt signals/slots\nDifferent marker shapes are rendered using appropriate Qt drawing primitives\n\n\n\n\n\n\n\n\nRange: 1-20 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 2 pixels\n\n\n\n\n\nShow Points: Option to display open circles at each data point along the line\nEdge Snapping: Enable automatic snapping to detected edges when adding points\nColor and Alpha: Configurable line color and transparency\n\n\n\n\n\nLine configuration is stored in the LineDisplayOptions structure\n\nLine thickness is applied via QPen::setWidth() during rendering\nUI controls follow the same synchronization pattern as point controls\nReal-time updates are supported via Qt signals/slots\n\n\n\n\n\n\n\nstruct PointDisplayOptions : public BaseDisplayOptions {\n    int point_size{DefaultDisplayValues::POINT_SIZE};\n    PointMarkerShape marker_shape{DefaultDisplayValues::POINT_MARKER_SHAPE};\n};\n\nstruct LineDisplayOptions : public BaseDisplayOptions {\n    int line_thickness{DefaultDisplayValues::LINE_THICKNESS};\n    bool show_points{DefaultDisplayValues::SHOW_POINTS};\n    bool edge_snapping{false};\n};\n\n\n\n\nMediaPoint_Widget handles point-specific controls\nMediaLine_Widget handles line-specific controls\nMedia_Window applies the configurations during rendering\nSynchronized UI controls prevent user confusion\n\n\n\n\nThe rendering system in Media_Window applies the display options during the plotting phase: - Point markers are drawn using the configured size and shape - Lines are drawn using the configured thickness via QPen - All configurations support real-time updates without data loss\n\n\n\n\n\n\n\nSelect the data item from the feature table\nAdjust display options in the widget panel\nChanges are applied immediately to the visualization\nUse sliders for quick adjustments or spinboxes for precise values\n\n\n\n\n\nAll display options inherit from BaseDisplayOptions\nUI controls should use blockSignals() to prevent recursive updates\nFollow the established naming convention for slot functions\nAdd corresponding test cases for new display options\nDocument new features in this file"
  },
  {
    "objectID": "developer/point_display_options.html#overview",
    "href": "developer/point_display_options.html#overview",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "The display system in WhiskerToolbox allows users to customize the visual appearance of various data types including points and lines through configurable display options."
  },
  {
    "objectID": "developer/point_display_options.html#point-display-options",
    "href": "developer/point_display_options.html#point-display-options",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "Range: 1-50 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 5 pixels\n\n\n\n\nThe system supports six different marker shapes:\n\nCircle (default) - Filled circular marker\nSquare - Filled rectangular marker\n\nTriangle - Filled triangular marker pointing upward\nCross - Plus sign (+) shaped marker\nX - X-shaped marker (×)\nDiamond - Diamond shaped marker (rotated square)\n\n\n\n\n\nPoint configuration is stored in the PointDisplayOptions structure\nUI controls are synchronized to prevent conflicts\nReal-time updates are supported via Qt signals/slots\nDifferent marker shapes are rendered using appropriate Qt drawing primitives"
  },
  {
    "objectID": "developer/point_display_options.html#line-display-options",
    "href": "developer/point_display_options.html#line-display-options",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "Range: 1-20 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 2 pixels\n\n\n\n\n\nShow Points: Option to display open circles at each data point along the line\nEdge Snapping: Enable automatic snapping to detected edges when adding points\nColor and Alpha: Configurable line color and transparency\n\n\n\n\n\nLine configuration is stored in the LineDisplayOptions structure\n\nLine thickness is applied via QPen::setWidth() during rendering\nUI controls follow the same synchronization pattern as point controls\nReal-time updates are supported via Qt signals/slots"
  },
  {
    "objectID": "developer/point_display_options.html#technical-architecture",
    "href": "developer/point_display_options.html#technical-architecture",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "struct PointDisplayOptions : public BaseDisplayOptions {\n    int point_size{DefaultDisplayValues::POINT_SIZE};\n    PointMarkerShape marker_shape{DefaultDisplayValues::POINT_MARKER_SHAPE};\n};\n\nstruct LineDisplayOptions : public BaseDisplayOptions {\n    int line_thickness{DefaultDisplayValues::LINE_THICKNESS};\n    bool show_points{DefaultDisplayValues::SHOW_POINTS};\n    bool edge_snapping{false};\n};\n\n\n\n\nMediaPoint_Widget handles point-specific controls\nMediaLine_Widget handles line-specific controls\nMedia_Window applies the configurations during rendering\nSynchronized UI controls prevent user confusion\n\n\n\n\nThe rendering system in Media_Window applies the display options during the plotting phase: - Point markers are drawn using the configured size and shape - Lines are drawn using the configured thickness via QPen - All configurations support real-time updates without data loss"
  },
  {
    "objectID": "developer/point_display_options.html#usage-guidelines",
    "href": "developer/point_display_options.html#usage-guidelines",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "Select the data item from the feature table\nAdjust display options in the widget panel\nChanges are applied immediately to the visualization\nUse sliders for quick adjustments or spinboxes for precise values\n\n\n\n\n\nAll display options inherit from BaseDisplayOptions\nUI controls should use blockSignals() to prevent recursive updates\nFollow the established naming convention for slot functions\nAdd corresponding test cases for new display options\nDocument new features in this file"
  },
  {
    "objectID": "developer/file_io.html",
    "href": "developer/file_io.html",
    "title": "File IO",
    "section": "",
    "text": "Because Neuralizer is compatible with a wide range of data, its file IO needs to support a wide range of file formats. Some of these file formats will be pre-subscribed, such as data acquisition-specific formats for electrophysiology. Others are more specific to this package, such as for line data that varies over time. We must also be aware from the start that some electrophysiology file sizes can be expected to be larger than easy to work with on a regular desktop machine. For instance, Neuropixel probes record almost 400 channels at 20 kHz and are becoming more routine for use. Consequently, multiple file formats should have the ability to be easily memory-mapped and loaded from disk rather than loading the entire file into RAM.\n\n\n\nAnother important consideration from the start is that many of these data types will be incrementally adjusted. For instance, processing a video sequence frame by frame or manually adjusting the output of an automated algorithm requires changing some subset of data in a much larger scheme. For some of these file types that are greater than hundreds of megabytes, resaving an entire file for point manipulations could be onerous and time-consuming. Consequently, for some file types, it would be advantageous to use a key-value database type structure that allows us to easily make incremental adjustments and only save those changes, consequently saving data much more quickly. To my knowledge, this process is quite common in the wild but uncommon in neuroscience.\n\n\n\nThe process of data serialization and deserialization will be accomplished with the Captain Proto library. This is able to easily create binary files from more complex data structures, such as those that hold multiple lines of varying size per unit time. This library can define output file structures that are purely binary and would be saved and loaded as entire objects. Alternatively, different definitions can be used to save objects as key-value pairs; for instance, each time point can be the key and the data at that time can be the value.\n\n\n\nCaptain Proto does not perform memory mapping itself. Memory mapping is different across different types of file systems, so to maintain cross-platform use, we will need to either specify different interfaces for interacting with Captain Proto or we could use another third-party library that does this for us. Boost.Interprocess is commonly cited for this purpose, but there are others.\n\n\n\nFor key-value database structures, there are multiple libraries available. Many of these are mature and designed to work with servers of extremely large datasets, and some have been developed by very large companies. One of the most popular is called LMDB, but in my test cases, this appears to be not as great with Windows. Using this library requires specifying some maximum file size; on Linux, the resulting file size is only the size of the data, but with my testing on Windows, this large maximum file size seems to persist. An alternative database is RocksDB. This software is developed by Facebook, seems to be quite mature, and should also be able to save as a key-value pair across platforms.\n\n\n\nCurrently, the data that would benefit from key-value updates is only theoretical. Having a line for whiskers for each frame in a high-speed video of up to 200,000 frames results in a file size that is almost 300 MB. However, saving a binary file in its entirety when making whisker-specific updates through manual curation still takes less than a second to save and is not noticeable to the user. Consequently, I think prioritizing having binary outputs to save entire files and memory mapping of those binary file types that are read-only, such as for Neuropixel analog traces, may be the most desirable next feature. Key-value pairs with something like RocksDB should be remembered for the future, but I am going to make that less of a priority until I see a clear use case that would benefit.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#overview-of-file-io-requirements",
    "href": "developer/file_io.html#overview-of-file-io-requirements",
    "title": "File IO",
    "section": "",
    "text": "Because Neuralizer is compatible with a wide range of data, its file IO needs to support a wide range of file formats. Some of these file formats will be pre-subscribed, such as data acquisition-specific formats for electrophysiology. Others are more specific to this package, such as for line data that varies over time. We must also be aware from the start that some electrophysiology file sizes can be expected to be larger than easy to work with on a regular desktop machine. For instance, Neuropixel probes record almost 400 channels at 20 kHz and are becoming more routine for use. Consequently, multiple file formats should have the ability to be easily memory-mapped and loaded from disk rather than loading the entire file into RAM.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#incremental-data-adjustments-and-key-value-stores",
    "href": "developer/file_io.html#incremental-data-adjustments-and-key-value-stores",
    "title": "File IO",
    "section": "",
    "text": "Another important consideration from the start is that many of these data types will be incrementally adjusted. For instance, processing a video sequence frame by frame or manually adjusting the output of an automated algorithm requires changing some subset of data in a much larger scheme. For some of these file types that are greater than hundreds of megabytes, resaving an entire file for point manipulations could be onerous and time-consuming. Consequently, for some file types, it would be advantageous to use a key-value database type structure that allows us to easily make incremental adjustments and only save those changes, consequently saving data much more quickly. To my knowledge, this process is quite common in the wild but uncommon in neuroscience.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#serialization-with-captain-proto",
    "href": "developer/file_io.html#serialization-with-captain-proto",
    "title": "File IO",
    "section": "",
    "text": "The process of data serialization and deserialization will be accomplished with the Captain Proto library. This is able to easily create binary files from more complex data structures, such as those that hold multiple lines of varying size per unit time. This library can define output file structures that are purely binary and would be saved and loaded as entire objects. Alternatively, different definitions can be used to save objects as key-value pairs; for instance, each time point can be the key and the data at that time can be the value.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#memory-mapping-implementation",
    "href": "developer/file_io.html#memory-mapping-implementation",
    "title": "File IO",
    "section": "",
    "text": "Captain Proto does not perform memory mapping itself. Memory mapping is different across different types of file systems, so to maintain cross-platform use, we will need to either specify different interfaces for interacting with Captain Proto or we could use another third-party library that does this for us. Boost.Interprocess is commonly cited for this purpose, but there are others.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#key-value-database-libraries",
    "href": "developer/file_io.html#key-value-database-libraries",
    "title": "File IO",
    "section": "",
    "text": "For key-value database structures, there are multiple libraries available. Many of these are mature and designed to work with servers of extremely large datasets, and some have been developed by very large companies. One of the most popular is called LMDB, but in my test cases, this appears to be not as great with Windows. Using this library requires specifying some maximum file size; on Linux, the resulting file size is only the size of the data, but with my testing on Windows, this large maximum file size seems to persist. An alternative database is RocksDB. This software is developed by Facebook, seems to be quite mature, and should also be able to save as a key-value pair across platforms.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/file_io.html#prioritization-and-future-considerations",
    "href": "developer/file_io.html#prioritization-and-future-considerations",
    "title": "File IO",
    "section": "",
    "text": "Currently, the data that would benefit from key-value updates is only theoretical. Having a line for whiskers for each frame in a high-speed video of up to 200,000 frames results in a file size that is almost 300 MB. However, saving a binary file in its entirety when making whisker-specific updates through manual curation still takes less than a second to save and is not noticeable to the user. Consequently, I think prioritizing having binary outputs to save entire files and memory mapping of those binary file types that are read-only, such as for Neuropixel analog traces, may be the most desirable next feature. Key-value pairs with something like RocksDB should be remembered for the future, but I am going to make that less of a priority until I see a clear use case that would benefit.",
    "crumbs": [
      "File IO"
    ]
  },
  {
    "objectID": "developer/Features/Collapsible_Widget.html",
    "href": "developer/Features/Collapsible_Widget.html",
    "title": "Collapsible Widget",
    "section": "",
    "text": "We have a Collapsible Widget called a “Section” available. This kind of widget can expand to display the contents of the widget. This is useful for making an interface appear less cluttered.\n\nGeneral process for to add collapsible Widget:\nQT Designer:\n\nEnsure the parent widget is in a vertical layout\nCreate QWidget inside and promote it to a “Section”\nCreate another QWidget within that QWidget. The inner QWidget will hold all the contents of the section.\nPopulate this inner QWidget with widgets as normal.\n\nCode part:\n\nCall autoSetContentLayout() on the Section QWidget after setupUi.\nOptionally, calling setTitle(\"title\") will give it a title.",
    "crumbs": [
      "Features",
      "Collapsible Widget"
    ]
  },
  {
    "objectID": "developer/data_viewer_widget.html",
    "href": "developer/data_viewer_widget.html",
    "title": "Data Viewer Widget",
    "section": "",
    "text": "The data viewer widget is designed for visualizing plots of time series data. It can operate on multiple distinct data types, such as analog time series, interval series, and event series. The widget contains a table of compatible data types and their corresponding keys, which can be selected for display in the viewer. It houses options to enable the visualization of different types and also includes an OpenGL canvas responsible for rendering the data according to user specifications.",
    "crumbs": [
      "Data Viewer Widget"
    ]
  },
  {
    "objectID": "developer/data_viewer_widget.html#event-viewer-features",
    "href": "developer/data_viewer_widget.html#event-viewer-features",
    "title": "Data Viewer Widget",
    "section": "Event Viewer Features",
    "text": "Event Viewer Features\nThe EventViewer_Widget provides controls for digital event series visualization with two main display modes:\n\nDisplay Modes\n\nStacked Mode (Default): Events are positioned in separate horizontal lanes with configurable spacing\n\nEach event series gets its own horizontal “lane”\nConfigurable vertical spacing between lanes\nConfigurable event line height\nAuto-calculation of optimal spacing when event groups are loaded\n\nFull Canvas Mode: Events stretch from top to bottom of the entire canvas\n\nOriginal behavior maintained for compatibility\nAll events span the full height of the display area\n\n\n\n\nAuto-Spacing for Event Groups\nWhen a tree of digital event series is selected and enabled, the system automatically calculates optimal spacing to fit all events on the canvas:\n\nIf 40 events are enabled on a 400-pixel tall canvas, each event gets approximately 10 pixels of space\nSpacing and height are calculated to ensure visual separation between different event series\nUses 80% of available canvas height, leaving margins at top and bottom\nEvent height is set to 60% of calculated spacing to prevent overlap\n\n\n\nUser Controls\nThe EventViewer_Widget provides: - Display Mode: Combo box to switch between Stacked and Full Canvas modes - Vertical Spacing: Adjustable spacing between stacked event series (0.01-1.0 normalized units) - Event Height: Adjustable height of individual event lines (0.01-0.5 normalized units) - Color Controls: Standard color picker for event line colors and transparency\n\n\nImplementation Details\n\nEvent stacking uses normalized coordinates for consistent spacing across different canvas sizes\nState is preserved when switching between data series\nIntegration with existing TreeWidgetStateManager for persistence\nOptimized rendering with proper OpenGL line thickness and positioning\n\n\n\nTime Frame Synchronization\nThe DataViewer Widget properly handles multi-rate data synchronization:\n\nMaster Time Frame: OpenGLWidget maintains a reference to the master time frame (“master” or “time”) used for X-axis coordinates\nTime Frame Conversion: When data series use different time frames from the master, proper coordinate conversion ensures synchronized display\nCross-Rate Compatibility: Supports simultaneous visualization of data collected at different sampling rates (e.g., 30kHz electrophysiology with 500Hz video)\nConsistent X-Axis: All data types (analog time series, digital events, digital intervals) are rendered with consistent X-axis positioning regardless of their native time frame\nRange Query Optimization: Data range queries are optimized for each time frame to ensure efficient rendering of large datasets",
    "crumbs": [
      "Data Viewer Widget"
    ]
  },
  {
    "objectID": "developer/data_viewer_widget.html#interactive-interval-editing",
    "href": "developer/data_viewer_widget.html#interactive-interval-editing",
    "title": "Data Viewer Widget",
    "section": "Interactive Interval Editing",
    "text": "Interactive Interval Editing\nThe DataViewer Widget supports interactive editing of digital interval series through a mouse-based dragging interface that handles multi-timeframe data seamlessly.\n\nInterval Selection and Highlighting\n\nClick-to-Select: Users can click on digital intervals to select them for editing\nVisual Feedback: Selected intervals are highlighted with enhanced borders for clear identification\nPer-Series Selection: Each digital interval series maintains its own independent selection state\n\n\n\nInterval Edge Dragging\nThe widget provides precise interval boundary editing through a sophisticated dragging system:\n\nCore Functionality\n\nEdge Detection: Mouse hover near interval boundaries (within 10 pixels) changes cursor to resize indicator\nDrag Initiation: Click and drag on interval edges to modify interval start or end times\nReal-time Preview: During dragging, both original (dimmed) and new (semi-transparent) interval positions are shown\nCollision Prevention: Automatic constraint enforcement prevents intervals from overlapping with existing intervals\n\n\n\nMulti-Timeframe Support\nThe interval dragging system automatically handles time frame conversion for data collected at different sampling rates:\n\nCoordinate Conversion: Mouse coordinates (in master time frame) are automatically converted to the series’ native time frame indices\nPrecision Handling: Dragged positions are rounded to the nearest valid index in the target time frame, accommodating different sampling resolutions\nConstraint Enforcement: Collision detection and boundary constraints are performed in the series’ native time frame for accuracy\nDisplay Consistency: Visual feedback remains in master time frame coordinates for consistent user experience\n\n\n\nError Handling and Robustness\n\nGraceful Degradation: Failed time frame conversions abort the drag operation while preserving original data\nData Integrity: Invalid interval bounds (e.g., start ≥ end) are rejected without modifying existing data\nState Management: Drag operations can be cancelled (ESC key) to restore original interval boundaries\n\n\n\nExample Use Cases\n\nBehavioral Annotation: Researchers can precisely adjust behavioral event boundaries recorded at video frame rates (30-120 Hz) while viewing synchronized neural data at higher sampling rates (20-30 kHz)\nEvent Refinement: Fine-tune automatically detected events by dragging boundaries to match observed signal characteristics across different data modalities\nCross-Modal Synchronization: Align interval boundaries across different measurement systems with varying temporal resolutions\n\n\n\n\nTechnical Implementation\nThe interval editing system leverages the existing TimeFrame infrastructure:\n\nTimeFrame.getIndexAtTime(): Converts master time coordinates to series-specific indices\nTimeFrame.getTimeAtIndex(): Converts series indices back to master time coordinates for display\nAutomatic Snapping: Ensures all interval boundaries align with valid time points in the target series\nThread Safety: All operations maintain data consistency during concurrent access\n\nThis functionality enables precise temporal analysis workflows while abstracting away the complexity of multi-rate data synchronization from the end user.",
    "crumbs": [
      "Data Viewer Widget"
    ]
  },
  {
    "objectID": "developer/data_viewer_widget.html#vertical-space-coordination",
    "href": "developer/data_viewer_widget.html#vertical-space-coordination",
    "title": "Data Viewer Widget",
    "section": "Vertical Space Coordination",
    "text": "Vertical Space Coordination\nThe DataViewer_Widget includes a sophisticated vertical space management system that prevents overlap between different data types and ensures optimal use of screen real estate.\n\nVerticalSpaceManager\nThe VerticalSpaceManager class handles automatic positioning and scaling for all data series:\n\nOrder-preserving: New data positioned below existing data\nType-aware spacing: Different configurations for analog (larger heights), digital events (compact), and intervals (moderate)\nAuto-redistribution: Adding new series triggers recalculation to prevent overlap\nCanvas-independent: Uses normalized coordinates for flexibility\n\n\n\nMVP Matrix Architecture\nThe rendering system uses a systematic Model-View-Projection (MVP) matrix approach for consistent positioning and scaling across all data types:\n\nModel Matrix - Series-Specific Transforms\nHandles individual series positioning and scaling:\n// For VerticalSpaceManager-positioned series:\nModel = glm::translate(Model, glm::vec3(0, series_center_y, 0));  // Position\nModel = glm::scale(Model, glm::vec3(1, series_height * 0.5f, 1)); // Scale\n\n// For analog series, additional amplitude scaling:\nfloat amplitude_scale = 1.0f / (stdDev * scale_factor);\nModel = glm::scale(Model, glm::vec3(1, amplitude_scale, 1));\n\n\nView Matrix - Global Operations\nHandles operations applied to all series equally:\nView = glm::translate(View, glm::vec3(0, _verticalPanOffset, 0)); // Global panning\n\n\nProjection Matrix - Coordinate System Mapping\nMaps world coordinates to screen coordinates:\n// X axis: time range [start_time, end_time] → screen width\n// Y axis: world coordinates [min_y, max_y] → screen height\nProjection = glm::ortho(start_time, end_time, min_y, max_y);\n\n\nVertex Coordinate Systems\nVerticalSpaceManager Mode (recommended): - Vertices use normalized coordinates (-1 to +1 in local space) - Model matrix handles all positioning and scaling - Consistent across all data types\nLegacy Mode (backward compatibility): - Vertices use world coordinates directly - Positioning handled by coordinate calculations - Index-based spacing for events\n\n\nDetection of Positioning Mode\nThe system automatically detects which positioning mode to use:\n\nDigital Events: vertical_spacing == 0.0f signals VerticalSpaceManager mode\nAnalog Series: y_offset != 0.0f signals VerticalSpaceManager mode\n\nDigital Intervals: y_offset != 0.0f signals VerticalSpaceManager mode\n\nThis ensures backward compatibility while enabling the new systematic approach.",
    "crumbs": [
      "Data Viewer Widget"
    ]
  },
  {
    "objectID": "developer/data_viewer_widget.html#interval-editing-system",
    "href": "developer/data_viewer_widget.html#interval-editing-system",
    "title": "Data Viewer Widget",
    "section": "Interval Editing System",
    "text": "Interval Editing System",
    "crumbs": [
      "Data Viewer Widget"
    ]
  },
  {
    "objectID": "developer/data_manager_widget.html",
    "href": "developer/data_manager_widget.html",
    "title": "Data Manager Widget",
    "section": "",
    "text": "Data Manager Widget Overview\nThe data manager widget serves as the main user interface for interacting with all data currently loaded into the program. At its top, the widget displays all keys currently in the data manager along with their corresponding data types. It enables the user to specify the folder for saving data. Additionally, users can create new, initially blank data sets, which can subsequently be populated through further manipulations and other widgets.\nWhen a user selects an entry in the top table, a data type-specific soft widget is populated. This widget presents the user with various features of the selected data. For example, when dealing with point data, it shows a table listing every available point within that data set and its associated frame. The user has the ability to scroll through this table; clicking an entry causes the time displayed by the rest of the program to jump to that point’s frame. Users can perform several data manipulations via these specific widgets. For instance, using the point widget, a user can delete any specific point. They can also opt to move a specific point to another point data set available in the manager.\n\n\nData Saving Functionality\nThe data manager widget also functions as the primary interface for saving data to disk. It features a sub-widget interface where the user can select the desired file output type, and specific options for that output type are then displayed. For instance, if a user is viewing point data, they can choose to output CSV files and will be presented with various CSV saving options, such as selecting the delimiter and deciding whether a header should be included, etc.",
    "crumbs": [
      "Data Manager Widget"
    ]
  },
  {
    "objectID": "developer/contributing_code.html",
    "href": "developer/contributing_code.html",
    "title": "Contributing Code",
    "section": "",
    "text": "Header files should use the hpp suffix, and source files should use the cpp suffix\nIncludes should follow the “Lakos” include order, that is\n\nThe prototype/interface header for this implementation (ie, the .h/.hh file that corresponds to this .cpp/.cc file).\nOther headers from the same project, as needed.\nHeaders from other non-standard, non-system libraries (for example, Qt, Eigen, etc).\nHeaders from other “almost-standard” libraries (for example, Boost)\nStandard C++ headers (for example, iostream, functional, etc.)\nStandard C headers (for example, cstdint, dirent.h, etc.)\n\nPrefer returning std::optional as a mechanism of error handling\nThis is a scientific computing library. Performance is critical. Helping the user to understand where errors have occurred is helpful, but keeping the program alive after an error is not critical. Functions should fail gracefully and provide informative error messages when they do. Logging should use spdlog.\nPrefer free functions as much as possible. Ideally, class member functions will be simple and pass member variables to free functions.\nPrefer standard library algorithms where possible\nPublic member functions and free function declarations should include doxygen comments above them. Private member function definitions should include doxygen comments above them.\nPrefer forward declarations in header files\nDocument pre-conditions and post-conditions in doxygen comments uses the @pre and @post tags.\nThis is a C++20 project. Prefer standard library algorithms and std::ranges where possible.",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#design-guidelines",
    "href": "developer/contributing_code.html#design-guidelines",
    "title": "Contributing Code",
    "section": "",
    "text": "Header files should use the hpp suffix, and source files should use the cpp suffix\nIncludes should follow the “Lakos” include order, that is\n\nThe prototype/interface header for this implementation (ie, the .h/.hh file that corresponds to this .cpp/.cc file).\nOther headers from the same project, as needed.\nHeaders from other non-standard, non-system libraries (for example, Qt, Eigen, etc).\nHeaders from other “almost-standard” libraries (for example, Boost)\nStandard C++ headers (for example, iostream, functional, etc.)\nStandard C headers (for example, cstdint, dirent.h, etc.)\n\nPrefer returning std::optional as a mechanism of error handling\nThis is a scientific computing library. Performance is critical. Helping the user to understand where errors have occurred is helpful, but keeping the program alive after an error is not critical. Functions should fail gracefully and provide informative error messages when they do. Logging should use spdlog.\nPrefer free functions as much as possible. Ideally, class member functions will be simple and pass member variables to free functions.\nPrefer standard library algorithms where possible\nPublic member functions and free function declarations should include doxygen comments above them. Private member function definitions should include doxygen comments above them.\nPrefer forward declarations in header files\nDocument pre-conditions and post-conditions in doxygen comments uses the @pre and @post tags.\nThis is a C++20 project. Prefer standard library algorithms and std::ranges where possible.",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#before-you-submit-a-pull-request",
    "href": "developer/contributing_code.html#before-you-submit-a-pull-request",
    "title": "Contributing Code",
    "section": "Before You Submit a Pull Request",
    "text": "Before You Submit a Pull Request\n\nClang Format\nPlease make sure to run clang-format on all of your submitted files with the style guidelines in the base directory. A CI check will ensure that this happens upon pull request. You can read more about clang-format here:\nhttps://clang.llvm.org/docs/ClangFormat.html\n\n\nClang Tidy\nPlease make sure to run clang-tidy on all of your submitted files with the style guidelines in the base directory. A CI check will ensure that this happens upon pull request. You can read more about clang-tidy here:\nhttps://clang.llvm.org/extra/clang-tidy/",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#testing",
    "href": "developer/contributing_code.html#testing",
    "title": "Contributing Code",
    "section": "Testing",
    "text": "Testing\n\nTesting is performed with Catch2. \nThe component being tested generally has two TEST_CASE parts. The first will test the “happy path” to ensure that the computations work as expected. Different SECTIONs will be used for different computations. A second TEST_CASE will handle error handling and edge cases. Each SECTION will be for a different edge case / error.\nUse descriptive names for each test.\nTEST_CASEs should also use useful tags.\nUse REQUIRE instead of CHECK\nSimple setup can be performed in the beginning of a TEST_CASE. Fixtures are only necessary for complex setup/teardown.\nPrefer Catch::Matchers::WithinRel to Catch::Approx\nTest files are included in the same folder as a given translation unit. They should have the same name as the header file with the extension “.test.cpp”. For example mask_to_line.hpp and mask_to_line.cpp will have the test file mask_to_line.test.cpp.",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "developer/contributing_code.html#further-resources-and-references",
    "href": "developer/contributing_code.html#further-resources-and-references",
    "title": "Contributing Code",
    "section": "Further Resources and References",
    "text": "Further Resources and References\n\nLLM Support\nA configuration file for a plain text generator, repo-to-text, is included in the top level source directory. This can generate a single text file for the entire Neuralyzer repository which can be easily pasted into a LLM of choice.\n\n\nTesting\n\nC++ Development\nMike Shah has an excellent modern C++ design series on youtube. Episodes are a nice ~20 minute length:\nModern Cpp series by Mike Shah\n\n\nGraphics Programming\nMike Shah also has a series on modern OpenGL on youtube:\nIntroduction to OpenGL",
    "crumbs": [
      "Contributing Code"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "developer/data_manager.html",
    "href": "developer/data_manager.html",
    "title": "Data Manager",
    "section": "",
    "text": "The DataManager has 3 core functionalities",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_manager.html#time-frame-structure-for-multi-rate-data-visualization",
    "href": "developer/data_manager.html#time-frame-structure-for-multi-rate-data-visualization",
    "title": "Data Manager",
    "section": "Time Frame Structure for Multi-Rate Data Visualization",
    "text": "Time Frame Structure for Multi-Rate Data Visualization\nAn important feature of the program is being able to simultaneously visualize data that was collected at different sampling rates. The time frame structure is designed to indicate when time events occur at a particular sampling frequency. The data manager is responsible for keeping track of which data is located in what time frame. Multiple data objects can belong to one time frame, but one data object can only belong to a single time frame. However, if the relationship between time frame objects is specified, then data requested in one coordinate system can be converted to another.\n\nIllustrative Example: Electrophysiology and Video Data\nConsider the following example: an NI-DAQ box samples at 30000 Hz for electrophysiology. This results in analog data with 30000 samples per second as well as event data for sorted spikes at 30000 Hz resolution. The experiment may have also had a high-speed video camera collecting frames at 500 Hz. A digital event for each frame was recorded with the same NI-DAQ. The user may have processed the video frames to categorize behavior, which would also be at the 500 Hz resolution and be interval data.\n\n\nDefault Time Frame and Customization\nThe default time frame is simply called “time” and defaults to numbers between 1 and the number of frames in a loaded video. The scroll bar operates in this time frame and consequently sends signals in this time frame. The user can override this default time frame and replace it with an event structure with the same number of samples but where each event corresponds to the 30000 Hz resolution digitized camera frame exposures. The user can then create a new clock called “master” that again counts from 1,2,3,… up to the total number of samples collected by the NI-DAQ.\n\n\nData Indexing within Time Frames\nAll data manager data types have a notion of “index,” and these correspond to the time frame they are associated with. This index property is important because data may be sparsely labeled and not have the same number of samples as their time frame.\n\n\nWidget Considerations for Data Synchronization\nWidgets that represent different data simultaneously must be aware of accounting for these differences.\n\n\nPerformance Notes\nThe user should also be aware that pointer indirections sample by sample for large vectors will be quite inefficient. If the user needs to find a series of values in a range in a different coordinate system it is most likely important to.",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_manager.html#observer-framework",
    "href": "developer/data_manager.html#observer-framework",
    "title": "Data Manager",
    "section": "Observer Framework",
    "text": "Observer Framework",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_manager.html#data-types",
    "href": "developer/data_manager.html#data-types",
    "title": "Data Manager",
    "section": "Data Types",
    "text": "Data Types\n\nPoint\nA Point represents a 2 dimensional (x, y) coordinate, which may vary in time. The PointData structure can hold multiple points per unit time.\n\n\n\nExamples of Point Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLine\nA Line represents a 2 dimensional (x,y) collection of points, which may vary with time. The collection of points is ordered, meaning that each point is positioned relative to its neighbors. The LineData structure can hold multiple lines per unit time.\n\n\n\nExamples of Line Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrently, lines are represented by a raw list of points. One could imagine lines being parameterized in different ways, such as the coefficients of a polynomial fit. For many calculations, the parameterized version of a line may be less memory intensive and more efficient.\n\n\nMask\nA mask represents a 2 dimensional collection of points, which may vary with time. Compared to a Line, the points in a Mask are not ordered. These would correspond to something like a binary segmentation mask over an image. The MaskData structure can hold multiple masks per unit time.\n\n\n\nExamples of Mask Data\n\n\n\n\nBinary Semantic Segmentation Labels\n\n\n\n\n\n\n\n\n\nA mask may just be thought as a raw pixel, by pixel definition of a shape. Shapes could be defined as bounding boxes, circles, polygons, etc. It may one day be useful to describe shapes in other ways compared to the raw pixel-by-pixel definition.\n\n\nTensors\nTensors are N-Dimensional data structures, and consequently very flexible containers for complex data. A concrete use would be to store a Height x Width x Channel array for different timepoints during an experiment. These may be the features output from an encoder neural network that processes a video.\n\n\n\nExamples of Tensor Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalog Time Series\nAn analog time series has values that can vary continuously\n\n\n\nExamples of Analog Time Series Data\n\n\n\n\nVoltage traces from electrode recordings\n\n\nFluorescence intensity traces from Calcium imaging\n\n\n\n\n\n\n\n\nDigital Event Series\nA digital event represents an ordered sequence of events, where each event is represented as a single instance in time. For instance, spike times from electrophysiology\n\n\n\nExamples of Event Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Interval Series\n\n\n\nExamples of Interval Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia\nMedia is a sequence of images.\n\nImage\n\n\n\nExamples of Image Data\n\n\n\n\nImage sequence from two photon calcium imaging experiment\n\n\n\n\n\n\n\n\n\n\n\nVideo\n\n\n\nExamples of Video Data\n\n\n\n\nMP4 video from high speed scientific camera of behavior\n\n\n\n\n\n\n\n\n\n\n\n\nTime Frame",
    "crumbs": [
      "Data Manager"
    ]
  },
  {
    "objectID": "developer/data_transform_widget.html",
    "href": "developer/data_transform_widget.html",
    "title": "Data Transform Widget",
    "section": "",
    "text": "The data transform interface is used for processing different data types. The core idea is to define various data processing operations that can be dynamically discovered and applied to different types of data, with parameters configurable through the UI. The system employs several design patterns, most notably the Strategy pattern for individual transformations and a Registry pattern for managing them, along with Factory Method for creating UI components."
  },
  {
    "objectID": "developer/data_transform_widget.html#core-components-and-workflow",
    "href": "developer/data_transform_widget.html#core-components-and-workflow",
    "title": "Data Transform Widget",
    "section": "Core Components and Workflow",
    "text": "Core Components and Workflow\nThe system revolves around a few key components:\n\nTransformOperation (Strategy Pattern): This is an abstract base class that defines the interface for all data transformation operations. Each concrete operation (e.g., EventThresholdOperation, MaskAreaOperation) inherits from TransformOperation and implements methods like getName(), getTargetInputTypeIndex(), canApply(), and execute(). This allows different algorithms (strategies) for data transformation to be used interchangeably.\nTransformParametersBase and derived structs (e.g., ThresholdParams): These structures hold the parameters for specific transformations. TransformParametersBase is a base class, and each operation can define its own derived struct (like ThresholdParams for thresholding operations) to store specific settings.\nTransformRegistry (Registry Pattern): This class acts as a central repository for all available TransformOperation instances. On initialization, it registers various concrete operation objects (e.g., MaskAreaOperation, EventThresholdOperation). It provides methods to find operations by name and to get a list of applicable operations for a given data type.\nTransformParameter_Widget (UI Abstraction): This is an abstract base class for UI widgets that allow users to set parameters for a TransformOperation. Concrete classes like AnalogEventThreshold_Widget inherit from it and provide the specific UI controls (e.g., spinboxes, comboboxes) for an operation.\nDataTransform_Widget (Main UI Controller): This Qt widget orchestrates the user interaction for data transformations.\n\nIt uses a Feature_Table_Widget to display available data items (features) from a DataManager.\nWhen a feature is selected, it queries the TransformRegistry to find applicable operations for that feature’s data type.\nIt populates a QComboBox with the names of these operations.\nWhen an operation is selected, it uses a map of factory functions (_parameterWidgetFactories) to create and display the appropriate TransformParameter_Widget (e.g., AnalogEventThreshold_Widget) for that operation. This is an example of the Factory Method pattern.\nIt has a “Do Transform” button that, when clicked, retrieves the parameters from the current TransformParameter_Widget, gets the selected TransformOperation from the TransformRegistry, and executes the operation on the selected data."
  },
  {
    "objectID": "developer/data_transform_widget.html#features",
    "href": "developer/data_transform_widget.html#features",
    "title": "Data Transform Widget",
    "section": "Features",
    "text": "Features\n\nThe ProgressCallback mechanism allows the TransformOperation to notify the DataTransform_Widget about its progress, which then updates the UI. This is a simple form of the Observer pattern."
  },
  {
    "objectID": "developer/display_options.html",
    "href": "developer/display_options.html",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "The display system in WhiskerToolbox allows users to customize the visual appearance of various data types including points and lines through configurable display options.\n\n\n\n\n\n\nRange: 1-50 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 5 pixels\n\n\n\n\nThe system supports six different marker shapes:\n\nCircle (default) - Filled circular marker\nSquare - Filled rectangular marker\n\nTriangle - Filled triangular marker pointing upward\nCross - Plus sign (+) shaped marker\nX - X-shaped marker (×)\nDiamond - Diamond shaped marker (rotated square)\n\n\n\n\n\nPoint configuration is stored in the PointDisplayOptions structure\nUI controls are synchronized to prevent conflicts\nReal-time updates are supported via Qt signals/slots\nDifferent marker shapes are rendered using appropriate Qt drawing primitives\n\n\n\n\n\n\n\n\nRange: 1-20 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 2 pixels\n\n\n\n\n\nShow Points: Option to display open circles at each data point along the line\nEdge Snapping: Enable automatic snapping to detected edges when adding points\nPosition Marker: Display a marker at a specified percentage distance along the line (off by default)\n\nshow_position_marker (bool): Enable/disable position marker display\nposition_percentage (int, 0-100%): Position along line where marker appears\n\nLine Segment: Display only a portion of the line between two percentage points (off by default)\n\nshow_segment (bool): Enable/disable segment-only display mode\nsegment_start_percentage (int, 0-100%): Start percentage for line segment\nsegment_end_percentage (int, 0-100%): End percentage for line segment\n\nColor and Alpha: Configurable line color and transparency\n\n\n\n\n\nRange: 0-100% along the cumulative length of the line\nUI Controls:\n\nCheckbox to enable/disable the feature (off by default)\nHorizontal slider for quick adjustments\nSpin box for precise numeric input with % suffix\n\nDefault Value: 20% along the line\nVisual Appearance: Distinctive filled circle with white border, same color as the line\nCalculation: Based on cumulative distance along line segments, not point indices\n\n\n\n\n\nLine configuration is stored in the LineDisplayOptions structure\n\nLine thickness is applied via QPen::setWidth() during rendering\nPosition marker calculated using cumulative distance along line segments\nUI controls follow the same synchronization pattern as point controls\nReal-time updates are supported via Qt signals/slots\n\n\n\nThe segment feature allows displaying only a portion of the line between two percentage points along its cumulative distance:\n\nget_segment_between_percentages(): Utility function in lines.hpp that extracts a continuous segment\n\nCalculates cumulative distances along the original line\nPerforms linear interpolation for precise start/end points\nReturns a new Line2D containing only the specified segment\nHandles edge cases (empty lines, invalid percentages, zero-length segments)\n\nUI Validation: Start percentage cannot exceed end percentage (enforced in UI)\nRendering Logic: When enabled, replaces the full line with the extracted segment in all rendering operations\nPosition Marker Compatibility: Position markers work correctly with segments (percentage relative to segment, not original line)\n\n\n\n\nThe bounding box feature provides a visual outline around mask regions:\n\nget_bounding_box(): Utility function in masks.hpp that calculates min/max coordinates\n\nIterates through all mask points to find extrema\nReturns pair of Point2D representing opposite corners\nHandles single-point masks correctly\n\nRendering Logic: Draws unfilled rectangles using Qt’s addRect() with Qt::NoBrush\nCoordinate Scaling: Applies same aspect ratio scaling as mask data\nMultiple Masks: Each mask gets its own bounding box when feature is enabled\nTime Handling: Bounding boxes are drawn for both current time and time -1 masks\nContainer Management: Uses separate _mask_bounding_boxes container (similar to digital intervals) to avoid type conflicts\n\n\n\n\n\n\n\n\n\n\n\nstruct PointDisplayOptions : public BaseDisplayOptions {\n    int point_size{DefaultDisplayValues::POINT_SIZE};\n    PointMarkerShape marker_shape{DefaultDisplayValues::POINT_MARKER_SHAPE};\n};\n\nstruct LineDisplayOptions : public BaseDisplayOptions {\n    int line_thickness{DefaultDisplayValues::LINE_THICKNESS};\n    bool show_points{DefaultDisplayValues::SHOW_POINTS};\n    bool edge_snapping{false};\n    bool show_position_marker{false};\n    int position_percentage{20};\n};\n\n\n\n\nMediaPoint_Widget handles point-specific controls\nMediaLine_Widget handles line-specific controls\nMedia_Window applies the configurations during rendering\nSynchronized UI controls prevent user confusion\n\n\n\n\nThe rendering system in Media_Window applies the display options during the plotting phase: - Point markers are drawn using the configured size and shape - Lines are drawn using the configured thickness via QPen - Position markers use get_position_at_percentage() for accurate placement - All configurations support real-time updates without data loss\n\n\n\n\n\n\n\nSelect the data item from the feature table\nAdjust display options in the widget panel\nChanges are applied immediately to the visualization\nUse sliders for quick adjustments or spinboxes for precise values\nEnable position marker to highlight specific locations along lines\n\n\n\n\n\nAll display options inherit from BaseDisplayOptions\nUI controls should use blockSignals() to prevent recursive updates\nFollow the established naming convention for slot functions\nAdd corresponding test cases for new display options\nUse get_position_at_percentage() for accurate line position calculations\nDocument new features in this file\n\n\n\n\nMask data represents 2D regions or shapes that can be overlaid on the media canvas:\n\nColor and Alpha: Configurable mask color and transparency\nBounding Box: Display rectangular outline around the mask extent (off by default)\n\nshow_bounding_box (bool): Enable/disable bounding box display\n\n\n\n\n\n\n\n\nThe mask display system includes:\n\nColor and Alpha Control: Masks can be displayed with configurable colors and transparency levels\nBounding Box: Option to display a rectangular outline around each mask showing its bounds\nOutline Drawing: Option to display the mask boundary as a thick line by connecting extremal points\n\n\n\nWhen enabled, a bounding box renders a rectangle outline around each mask. The implementation: - Uses the existing get_bounding_box() utility function from masks.hpp - Scales coordinates properly with aspect ratios - Draws unfilled rectangles using Qt::NoBrush for outline-only appearance - Handles both current time and time -1 masks\n\n\n\nWhen enabled, displays the mask boundary as a thick line connecting extremal points. The algorithm: - For each unique x coordinate, finds the maximum y value - For each unique y coordinate, finds the maximum x value\n- Collects all extremal points and sorts them by angle from centroid - Connects points to form a closed boundary outline - Renders as a thick 4-pixel wide line using QPainterPath\nThe outline feature uses the get_mask_outline() function to compute boundary points by finding extremal coordinates, providing a visual representation of the mask’s outer boundary."
  },
  {
    "objectID": "developer/display_options.html#overview",
    "href": "developer/display_options.html#overview",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "The display system in WhiskerToolbox allows users to customize the visual appearance of various data types including points and lines through configurable display options."
  },
  {
    "objectID": "developer/display_options.html#point-display-options",
    "href": "developer/display_options.html#point-display-options",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "Range: 1-50 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 5 pixels\n\n\n\n\nThe system supports six different marker shapes:\n\nCircle (default) - Filled circular marker\nSquare - Filled rectangular marker\n\nTriangle - Filled triangular marker pointing upward\nCross - Plus sign (+) shaped marker\nX - X-shaped marker (×)\nDiamond - Diamond shaped marker (rotated square)\n\n\n\n\n\nPoint configuration is stored in the PointDisplayOptions structure\nUI controls are synchronized to prevent conflicts\nReal-time updates are supported via Qt signals/slots\nDifferent marker shapes are rendered using appropriate Qt drawing primitives"
  },
  {
    "objectID": "developer/display_options.html#line-display-options",
    "href": "developer/display_options.html#line-display-options",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "Range: 1-20 pixels\nUI Controls:\n\nHorizontal slider for quick adjustments\nSpin box for precise numeric input\nSynchronized controls (changing one updates the other)\n\nDefault Value: 2 pixels\n\n\n\n\n\nShow Points: Option to display open circles at each data point along the line\nEdge Snapping: Enable automatic snapping to detected edges when adding points\nPosition Marker: Display a marker at a specified percentage distance along the line (off by default)\n\nshow_position_marker (bool): Enable/disable position marker display\nposition_percentage (int, 0-100%): Position along line where marker appears\n\nLine Segment: Display only a portion of the line between two percentage points (off by default)\n\nshow_segment (bool): Enable/disable segment-only display mode\nsegment_start_percentage (int, 0-100%): Start percentage for line segment\nsegment_end_percentage (int, 0-100%): End percentage for line segment\n\nColor and Alpha: Configurable line color and transparency\n\n\n\n\n\nRange: 0-100% along the cumulative length of the line\nUI Controls:\n\nCheckbox to enable/disable the feature (off by default)\nHorizontal slider for quick adjustments\nSpin box for precise numeric input with % suffix\n\nDefault Value: 20% along the line\nVisual Appearance: Distinctive filled circle with white border, same color as the line\nCalculation: Based on cumulative distance along line segments, not point indices\n\n\n\n\n\nLine configuration is stored in the LineDisplayOptions structure\n\nLine thickness is applied via QPen::setWidth() during rendering\nPosition marker calculated using cumulative distance along line segments\nUI controls follow the same synchronization pattern as point controls\nReal-time updates are supported via Qt signals/slots\n\n\n\nThe segment feature allows displaying only a portion of the line between two percentage points along its cumulative distance:\n\nget_segment_between_percentages(): Utility function in lines.hpp that extracts a continuous segment\n\nCalculates cumulative distances along the original line\nPerforms linear interpolation for precise start/end points\nReturns a new Line2D containing only the specified segment\nHandles edge cases (empty lines, invalid percentages, zero-length segments)\n\nUI Validation: Start percentage cannot exceed end percentage (enforced in UI)\nRendering Logic: When enabled, replaces the full line with the extracted segment in all rendering operations\nPosition Marker Compatibility: Position markers work correctly with segments (percentage relative to segment, not original line)\n\n\n\n\nThe bounding box feature provides a visual outline around mask regions:\n\nget_bounding_box(): Utility function in masks.hpp that calculates min/max coordinates\n\nIterates through all mask points to find extrema\nReturns pair of Point2D representing opposite corners\nHandles single-point masks correctly\n\nRendering Logic: Draws unfilled rectangles using Qt’s addRect() with Qt::NoBrush\nCoordinate Scaling: Applies same aspect ratio scaling as mask data\nMultiple Masks: Each mask gets its own bounding box when feature is enabled\nTime Handling: Bounding boxes are drawn for both current time and time -1 masks\nContainer Management: Uses separate _mask_bounding_boxes container (similar to digital intervals) to avoid type conflicts"
  },
  {
    "objectID": "developer/display_options.html#technical-architecture",
    "href": "developer/display_options.html#technical-architecture",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "struct PointDisplayOptions : public BaseDisplayOptions {\n    int point_size{DefaultDisplayValues::POINT_SIZE};\n    PointMarkerShape marker_shape{DefaultDisplayValues::POINT_MARKER_SHAPE};\n};\n\nstruct LineDisplayOptions : public BaseDisplayOptions {\n    int line_thickness{DefaultDisplayValues::LINE_THICKNESS};\n    bool show_points{DefaultDisplayValues::SHOW_POINTS};\n    bool edge_snapping{false};\n    bool show_position_marker{false};\n    int position_percentage{20};\n};\n\n\n\n\nMediaPoint_Widget handles point-specific controls\nMediaLine_Widget handles line-specific controls\nMedia_Window applies the configurations during rendering\nSynchronized UI controls prevent user confusion\n\n\n\n\nThe rendering system in Media_Window applies the display options during the plotting phase: - Point markers are drawn using the configured size and shape - Lines are drawn using the configured thickness via QPen - Position markers use get_position_at_percentage() for accurate placement - All configurations support real-time updates without data loss"
  },
  {
    "objectID": "developer/display_options.html#usage-guidelines",
    "href": "developer/display_options.html#usage-guidelines",
    "title": "Display Options for Media Widgets",
    "section": "",
    "text": "Select the data item from the feature table\nAdjust display options in the widget panel\nChanges are applied immediately to the visualization\nUse sliders for quick adjustments or spinboxes for precise values\nEnable position marker to highlight specific locations along lines\n\n\n\n\n\nAll display options inherit from BaseDisplayOptions\nUI controls should use blockSignals() to prevent recursive updates\nFollow the established naming convention for slot functions\nAdd corresponding test cases for new display options\nUse get_position_at_percentage() for accurate line position calculations\nDocument new features in this file\n\n\n\n\nMask data represents 2D regions or shapes that can be overlaid on the media canvas:\n\nColor and Alpha: Configurable mask color and transparency\nBounding Box: Display rectangular outline around the mask extent (off by default)\n\nshow_bounding_box (bool): Enable/disable bounding box display\n\n\n\n\n\n\n\n\nThe mask display system includes:\n\nColor and Alpha Control: Masks can be displayed with configurable colors and transparency levels\nBounding Box: Option to display a rectangular outline around each mask showing its bounds\nOutline Drawing: Option to display the mask boundary as a thick line by connecting extremal points\n\n\n\nWhen enabled, a bounding box renders a rectangle outline around each mask. The implementation: - Uses the existing get_bounding_box() utility function from masks.hpp - Scales coordinates properly with aspect ratios - Draws unfilled rectangles using Qt::NoBrush for outline-only appearance - Handles both current time and time -1 masks\n\n\n\nWhen enabled, displays the mask boundary as a thick line connecting extremal points. The algorithm: - For each unique x coordinate, finds the maximum y value - For each unique y coordinate, finds the maximum x value\n- Collects all extremal points and sorts them by angle from centroid - Connects points to form a closed boundary outline - Renders as a thick 4-pixel wide line using QPainterPath\nThe outline feature uses the get_mask_outline() function to compute boundary points by finding extremal coordinates, providing a visual representation of the mask’s outer boundary."
  },
  {
    "objectID": "developer/Features/overview.html",
    "href": "developer/Features/overview.html",
    "title": "Features",
    "section": "",
    "text": "Documentation of some of the general widget types in Neuralyzer.",
    "crumbs": [
      "Features"
    ]
  },
  {
    "objectID": "developer/media_widget.html",
    "href": "developer/media_widget.html",
    "title": "Media Widget",
    "section": "",
    "text": "The media widget is responsible for displaying data that can be visualized on a canvas. The types of data that can be displayed by the data manager include point data, line data, mask data, tensor data, interval data, and media data. Data currently in the data manager matching these types is displayed on the top left side. In this table, the user can click to enable the visibility of particular data in the accompanying media window canvas.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/media_widget.html#overview-and-data-display",
    "href": "developer/media_widget.html#overview-and-data-display",
    "title": "Media Widget",
    "section": "",
    "text": "The media widget is responsible for displaying data that can be visualized on a canvas. The types of data that can be displayed by the data manager include point data, line data, mask data, tensor data, interval data, and media data. Data currently in the data manager matching these types is displayed on the top left side. In this table, the user can click to enable the visibility of particular data in the accompanying media window canvas.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/media_widget.html#data-specific-interactions-and-manipulations",
    "href": "developer/media_widget.html#data-specific-interactions-and-manipulations",
    "title": "Media Widget",
    "section": "Data-Specific Interactions and Manipulations",
    "text": "Data-Specific Interactions and Manipulations\nClicking on a data item also brings up a sub-widget below the table, offering data type-specific manipulations. For example, this sub-widget would be responsible for changing attributes such as color, alpha value, marker type, etc., for point data within the media window. This sub-widget may also handle data-specific manipulations directly within the media window. For instance, the user might wish to click on a position in the media window to set it as the location for the currently displayed point. Alternatively, the user might click and hold to utilize a paintbrush-type function for extending or erasing mask data.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "developer/media_widget.html#shared-components-and-common-interactions",
    "href": "developer/media_widget.html#shared-components-and-common-interactions",
    "title": "Media Widget",
    "section": "Shared Components and Common Interactions",
    "text": "Shared Components and Common Interactions\nThese data-specific sub-widgets may house common sub-widgets that are shared among others. For instance, color selection is a common feature for multiple data types. An interface for click, hover, and release interactions is common to multiple data types but may perform different actions, such as painting a mask or erasing the media foreground.\nNote that there is some overlap here with the data manager widget. For many data types the data manager widget includes the ability to view all data present in the data manager and select particular instances such as a point at a certain time and the user can delete that point. Consequently we will try to keep media window based manipulation to the media widget. \nThe media window is the widget that houses the actual canvas for display. It is also the owner of the specific drawing options and drawing routines onto the canvas. For instance if the user changes the marker size and color of point data the options that are updated are held by the media window. The media window uses qt-based drawing. It is also responsible for receiving mouse events inside its space and emits signals that other widgets can receive.",
    "crumbs": [
      "Media Widget"
    ]
  },
  {
    "objectID": "user_guide/behaviors/tongue.html",
    "href": "user_guide/behaviors/tongue.html",
    "title": "Tongue Tracking",
    "section": "",
    "text": "The Tongue Tracking widget deals with operations related to the tongue.",
    "crumbs": [
      "Behavioral Modules",
      "Tongue Tracking"
    ]
  },
  {
    "objectID": "user_guide/behaviors/tongue.html#loading",
    "href": "user_guide/behaviors/tongue.html#loading",
    "title": "Tongue Tracking",
    "section": "Loading",
    "text": "Loading\nTongue masks can be loaded through the sparse HDF5 format or binary images (where white is part of the mask, black is not).\nJaw keypoint tracking can also be loaded through CSV format. The first column should indicate frame number, the next indicating \\(x\\) position and the next \\(y\\) position.",
    "crumbs": [
      "Behavioral Modules",
      "Tongue Tracking"
    ]
  },
  {
    "objectID": "user_guide/behaviors/tongue.html#grabcut-tool",
    "href": "user_guide/behaviors/tongue.html#grabcut-tool",
    "title": "Tongue Tracking",
    "section": "GrabCut Tool",
    "text": "GrabCut Tool\nDocumentation on the GrabCut tool can be found here.",
    "crumbs": [
      "Behavioral Modules",
      "Tongue Tracking"
    ]
  },
  {
    "objectID": "user_guide/data_transformations/overview.html",
    "href": "user_guide/data_transformations/overview.html",
    "title": "Data Transformations",
    "section": "",
    "text": "Data transformations are operations we perform on one kind of data that result in another kind of data.\nTransformations supported by Neuralyzer are listed below:",
    "crumbs": [
      "Data Transformations",
      "Data Transformations"
    ]
  },
  {
    "objectID": "user_guide/data_transformations/overview.html#transformations",
    "href": "user_guide/data_transformations/overview.html#transformations",
    "title": "Data Transformations",
    "section": "Transformations",
    "text": "Transformations\n\nAnalog Time Series\n\nEvent Detection by Threshold Crossing\nGenerate events from a time series by comparing signal to some threshold value.\nThreshold Value:\nThe numerical level the signal must cross to be considered an event. The signal will be compared directly against this value based on the selected direction.\nThreshold Direction:\nHow the signal must cross the Threshold Value to trigger an event:\n\nPositive (Rising): Detects an event only when the signal value increases and crosses above the Threshold Value.\nNegative (Falling): Detects an event only when the signal value decreases and crosses below the Threshold Value.\nAbsolute (Magnitude): Detects an event when the absolute value of the signal (abs(signal)) rises above the Threshold Value. This detects crossings away from zero on either the positive or negative side.\n\nLockout Time (Samples):\nThe minimum number of samples that must pass after an event is detected before another threshold crossing can trigger a new event. Enter 0 (or less) to disable the lockout, allowing consecutive samples to trigger events if they cross the threshold. This helps prevent multiple detections from a single noisy crossing.\n\n\nFind Peaks\nAttempts to find peaks in analog time series (local maxima or minima).\n\n\nInstantaneous Amplitude Calculation\nDetermine the instantaneous amplitude of an oscillatory time series. uses Hilbert Transform.\n\n\nInstantaneous Phase Calculation\nDetermine the instantaneous phase of an oscillatory time series. Uses Hilbert Transform.\n\n\nInterval Detection\nDetermine an interval range where an angle signal is above (or below) a threshold value. Returns the beginning and end of the above/below threshold time period.\nThreshold Value:\nDescription: Enter the numerical level the signal must cross to be considered an event. The signal will be compared directly against this value based on the selected direction. The interval will be defined from the first to last sample that are above or below the Threshold Value.\nThreshold Direction:\nDescription: Select how the signal must cross the Threshold Value to trigger an interval:\n\nPositive (Rising): Detects an interval only when the signal value increases and remains above the Threshold Value.\nNegative (Falling): Detects an event only when the signal value decreases and remains below the Threshold Value.\nAbsolute (Magnitude): Detects an event when the absolute value of the signal (abs(signal)) rises above the Threshold Value. This detects crossings away from zero on either the positive or negative side. Once the absolute value is smaller than the abs(signal), the interval has ended.\n\nLockout Time (Samples):\nDescription: Specify the minimum number of samples that must pass after an interval has ended before another threshold crossing can trigger a new event. Enter 0 (or less) to disable the lockout.\nMinimum Duration (Samples):\nDescription: Specify the minimum number of samples that must be in an interval to be included. Threshold crossings with durations shorter than Minimum Duration will not be included in result.\n\n\n\nMasks\n\nArea\nTotal area of the mask in a frame is calculated.",
    "crumbs": [
      "Data Transformations",
      "Data Transformations"
    ]
  },
  {
    "objectID": "user_guide/machine_learning/ML_intro.html",
    "href": "user_guide/machine_learning/ML_intro.html",
    "title": "Overview",
    "section": "",
    "text": "The Machine Learning Widget allows us to fit models of relationships between multiple features of our data and then make predictions. This can be useful for semi-automated annotation of datasets, where the user labels some training data, and then predicts the remaining unlabeled frames. Then annotations can then be easily compared with the video data.",
    "crumbs": [
      "Machine Learning",
      "Overview"
    ]
  },
  {
    "objectID": "examples/keypoint_labeling.html",
    "href": "examples/keypoint_labeling.html",
    "title": "Keypoint Video Labeling",
    "section": "",
    "text": "Video\n\n\n(^ this should be a gif)\nThis tutorial will show you how to add, review, and change key points located on frames throughout a video.\n\nLoad the video that you intend to label. Or, select Load JSON configuration if you have generated a key point .csv and would like to review the labels. (See: setting up a JSON file)\n\nOpen the data manager to create a new point feature\n\nSet the output directory for your key point-coordinate containing .csv file\nCreate a new point feature with the type: point\nTime frame should correspond to (x)\nName the point after the feature that you will be labeling\n\nEnable the feature in the media widget to open the point editor\nChange the color and opacity (Alpha) to ensure visibility\nChange the size and shape of the key point if needed\nChoose “select point” under mouse mode to begin adding points\nNOTE: the key point will always be represented by a single pixel and the marker shape information will not be retained\nTo add points, click anywhere in the media canvas to add a point. If a point already exists in the frame, the point will be moved.\n\nOnce labeling is finished, labeled frames and the feature coordinates will appear in the data manager when the new feature is selected.\nFrom here, the export selections can be made.\nThe delimiter will specify the separations between each column\nThe line ending will specify the separations made between each line\nThis text formatting information is useful for subsequent data analysis\n\nBy checking the “Export matching media frames” box, a new folder will be created in the output folder that will contain images of the frames that contain key points.\nNOTE: the key points will not be overlaid on the frame\n\nOnce done, click “Save to CSV”\nIf successful, your screen should look like this, and the key point data should be saved to the output folder defined earlier."
  }
]